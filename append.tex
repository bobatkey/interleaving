\RequirePackage{amsmath}
\documentclass{jfp1}

\usepackage{stmaryrd}

\usepackage[usenames]{color}
\usepackage{hyperref}
\hypersetup{colorlinks=true,
            pdftitle=Interleaving data and effects,
            pdfauthor={Robert Atkey, Patricia Johann, Neil Ghani, and Bart Jacobs},
            pdfkeywords={inductive types, initial algebras, effects, monads, eilenberg-moore algebras, interleaved data and effects}}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}


\newcommand{\fold}[1]{\llparenthesis #1 \rrparenthesis}
\newcommand{\eFold}[2]{\llparenthesis #1|#2 \rrparenthesis}
\newcommand{\fmext}[1]{\langle\kern-0.25em\langle #1 \rangle\kern-0.25em\rangle}
\newcommand{\construct}{\mathsf{in}}
\newcommand{\mbind}{\mathrel{>\kern-0.45em>\kern-0.45em=}}

\newcommand{\eqAnnotation}[1]{\hspace{2cm}\left\{\textrm{#1}\right\}}
\newcommand{\eqAnnotationS}[1]{\hspace{1cm}\left\{\textrm{#1}\right\}}

\newcommand{\cat}[1]{\mathcal{#1}}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{proofprinciple}{Proof Principle}

\newcommand{\proofprinref}[1]{\hyperref[#1]{Proof Principle \ref*{#1}}}
\newcommand{\thmref}[1]{\hyperref[#1]{Theorem \ref*{#1}}}
\newcommand{\defref}[1]{\hyperref[#1]{Definition \ref*{#1}}}

\newcommand{\kw}[1]{\textbf{#1}}

\title{Interleaving data and effects}

\author[R. Atkey, P. Johann, N. Ghani, B. Jacobs]
       {ROBERT ATKEY, PATRICIA JOHANN, NEIL GHANI \\
         University of Strathclyde, Glasgow, G1 1XH, UK \\
         \vspace{0.3cm}
         BART JACOBS \\
         Radboud University, Nijmegen, Netherlands
         \email{$\{$robert.atkey,patricia.johann,neil.ghani$\}$@strath.ac.uk, bart@cs.ru.nl}}


       
\begin{document}

\label{firstpage}

\maketitle

\begin{abstract}
  The study of programming with and reasoning about inductive
  datatypes such as lists and trees has benefited from the simple
  categorical principle of initial algebras. In initial algebra
  semantics, each inductive datatype is represented by an initial
  $f$-algebra for an appropriate functor $f$. The initial algebra
  principle then supports the straightforward derivation of
  definitional and proof principles for these datatypes.  This
  technique has been expanded to a whole methodology of structured
  functional programming, often called origami programming.

  In this article, we show how to extend initial algebra semantics
  from pure inductive datatypes to inductive datatypes interleaved
  with computational effects. Inductive datatypes interleaved with
  effects arise naturally in many computational settings. For example,
  incrementally reading characters from a file generates a list of
  characters interleaved with input/output actions. Straightforward
  application of initial algebra techniques to effectful datatypes
  leads to unnecessarily complicated reasoning, because the pure and
  effectful concerns must be considered simultaneously. We show how
  these concerns can be separated using Filinski and St\o{}vring's
  abstraction of initial $f$-and-$m$-algebras, where the functor $f$
  describes the pure part of a datatype, and the monad $m$ describes
  the interleaved effects. Because initial $f$-and-$m$-algebras are
  the analogue for the effectful setting of initial $f$-algebras, they
  support the extension of the standard definitional and proof
  principles to the effectful setting. Because initial
  $f$-and-$m$-algebras separate pure and effectful concerns, they
  support the direct transfer of definitions and proofs from the pure
  setting to the effectful setting.




% the running example of lists can be
%   interleaved with input/output actions. We demonstrate that the
%   abstraction of initial $f$-and-$m$-algebras, where $f$ is a functor and $m$ is a monad, originally due to
%   Filinski and St\o{}vring, is the appropriate way to reason about
%   such interleaved pure and effectful data.
\end{abstract}

\section{Introduction}

One of the attractions of functional programming is the ease by which
programmers may lift the level of abstraction. A central example is
the use of higher-order combinators for defining and reasoning about
programs that operate on recursively defined datatypes. For example,
recursive functions on lists can often by re-expressed in terms of the
higher-order function $\mathit{foldr}$, which has the type:
\begin{displaymath}
  \mathit{foldr} :: a \to (e \to a \to a) \to [e] \to a
\end{displaymath}
The benefits of expressing recursive functions in terms of combinators
like $\mathit{foldr}$, rather than through direct use of recursion,
are twofold. Firstly, we are automatically guaranteed several
desirable properties, such as totality (on finite input), without
having to do any further reasoning. Secondly, functions defined using
$\mathit{foldr}$ obey a uniqueness property that allows us to easily
derive further properties about them. The style of
programming that uses combinators such as $\mathit{foldr}$ and its
uniqueness property has become known as ``origami programming''
\cite{gibbons03origami}, and forms a key part of the general Algebra
of Programming methodology \cite{bdm97}.

Programming and reasoning using higher-order recursion combinators is
built upon the category theoretic foundation of initial $f$-algebras
for functors $f$ \cite{GoguenTW78}. In initial algebra semantics,
datatypes are represented by carriers of initial algebras --
i.e.~least fixed points of functors -- and combinators such as
$\mathit{foldr}$ are derived from the universal properties of initial
algebras. The initial $f$-algebra methodology has been successful in
unifying and clarifying structured functional programming and
reasoning on values of recursive datatypes that go far beyond lists
and $\mathit{foldr}$.

In this paper, we present a class of recursive datatypes where direct
use of the initial algebra methodology does \emph{not} provide the
right level of abstraction. Specifically, we consider recursive
datatypes that interleave pure data with effectful computation. For
example, lists of characters that are interleaved with the effectful
input computations that read them from some external source can be
described by the following datatype declaration:
\begin{displaymath}\label{defn:listio}
  \begin{array}{ll}
    \kw{data}~\mathit{List'_{io}}
    &
    \kw{newtype}~\mathit{List_{io}} = 
    \\
    \quad
    \begin{array}[t]{c@{\hspace{0.5em}}l}
      = & \mathsf{Nil_{io}} \\
      | & \mathsf{Cons_{io}}~\mathit{Char}~\mathit{List_{io}} \\
    \end{array}
    &
    \quad \mathsf{List_{io}}~(\mathit{IO}~\mathit{List'_{io}})
  \end{array}
\end{displaymath}
Using the initial $f$-algebra methology to program with and reason
about such datatypes forces us to mingle the pure and effectful parts
of our programs and proofs in a way that obscures their essential
properties (as we demonstrate in \autoref{sec:direct-eappend}). By
abstracting out the effectful parts, we arrive at the concept of
initial $f$-and-$m$-algebras, where $f$ is a functor whose initial
algebra that describes the datatype, and $m$ is a monad that describes
the effects. Initial $f$-and-$m$-algebras represent a better level of
abstraction for dealing with interleaved data and effects. The key
idea is to separate the concerns of dealing with pure data, via
$f$-algebras, and effects, via $m$-Eilenberg-Moore-algebras. We shall
see in \autoref{sec:f-and-m-append} that this separation has the
following benefits:
\begin{itemize}
\item \emph{Definitions} of functions on datatypes that interleave
  data and effects look very similar to their counterparts on pure
  datatypes. We will use the example of adapting the append function
  on lists to a datatype of lists interleaved with effects. The pure
  part of the computation remains the same, and the effectful part is
  straightforward. Therefore, definitions of functions on pure
  datatypes can often be transferred directly to their effectful
  counterparts.
\item \emph{Proofs} about functions on interleaved datatypes also
  carry over almost unchanged from their pure counterparts. We
  demonstrate this though the proof of associativity for append on
  effectful lists, which carries over almost unchanged from the proof
  of associativity of append for pure lists, except for an additional
  side condition that is discharged almost trivially.
\end{itemize}

The concept of initial $f$-and-$m$-algebras is originally due to
Filinski and St\o{}vring \cite{filinski07inductive}, and was
subsequently extended to a general category-theoretic setting by the
authors of the current paper \cite{atkey12fibrational}. In this paper,
we aim to introduce the concept of initial $f$-and-$m$-algebras to a
general functional programming audience.

\subsection{Interleaving data and effects}
\label{sec:motivate-interleaving}

To motivate the consideration of interleaved data and effects, we
consider a function in the Haskell standard library that is not as
straightfoward as its type implies. The $\mathit{hGetContents}$
function provides an example of \emph{implicit} interleaving of data
with effects. This function has the following type:
\begin{displaymath}
  \mathit{hGetContents} :: \mathit{Handle} \to \mathit{IO}~[\mathit{Char}]
\end{displaymath}
Reading the type of this function, one might assume that it operates
by reading all the available data from the file referenced by the
given handle as an $\mathit{IO}$ action, and then returning the list
of characters as pure data. In fact, the standard implementation of
this function postpones the input effects until the list is actually
accessed by the program. The effect of reading from the file handle is
implicitly \emph{interleaved} with any later pure computation on the
list. This interleaving is not made apparent in the type of
$\mathit{hGetContents}$, and this has the following undesirable
consequences:
\begin{itemize}
\item Input/output errors that occur during reading (e.g.,~network
  failure) are reported by throwing exceptions from pure code, using
  Haskell's imprecise exceptions facility. Since the actual reading
  may occur long after the call to $\mathit{hGetContents}$ has
  apparently finished, it can be extremely difficult to determine the
  scope in which such an exception was be thrown.
\item Since it is difficult to predict when the read effects will
  occur, it is no longer safe for the programmer to close the file
  handle. The handle is implicitly closed when the end of the file is
  reached. This means that if the string returned by
  $\mathit{hGetContents}$ is never completely read, the handle will
  never be closed. Since open file handles are a finite resource
  shared by all processes on a system, the non-deterministic closing
  of file handles can be a serious problem with long-running programs.
\end{itemize}
Despite these flaws, there are good reasons for wishing to interleave
the effect of reading with data processing. A primary one is that the
file being read may be larger than the available memory, so reading it
all into a buffer may not be possible. However, the type of
$\mathit{hGetContents}$ fails to make the interleaving explicit.

We can make the interleaving explicit by declaring a new type of lists
interleaved with some effects described by a monad $m$. This
generalises the definition of $\mathit{List_{io}}$ from
\hyperref[defn:listio]{Page \pageref*{defn:listio}}:
\begin{displaymath}
  \begin{array}{ll}
    \kw{data}~\mathit{List'}~m~a
    &
    \kw{newtype}~\mathit{List}~m~a = 
    \\
    \quad
    \begin{array}[t]{c@{\hspace{0.5em}}l}
      = & \mathsf{Nil_m} \\
      | & \mathsf{Cons_m}~a~(\mathit{List}~m~a) \\
    \end{array}
    &
    \quad \mathsf{List}~(m~(\mathit{List'}~m~a))
  \end{array}
\end{displaymath}
A value of type $\mathit{List}~m~a$ consists of an effect described by
$m$, then either a $\mathsf{Nil_m}$ to indicate the end of the list,
or a $\mathsf{Cons_m}$ with a value of type $a$ and more list. Thus
this datatype describes lists of values of type $a$ interleaved with
effects from the monad $m$.

We can re-implement $\mathit{hGetContents}$ to generate values of type
$\mathit{List}~\mathit{IO}~\mathit{Char}$. An simple implementation
can be given in terms of the standard Haskell primitives for
performing IO on file handles:
\begin{displaymath}
  \begin{array}{l}
  \mathit{hGetContents} :: \mathit{Handle} \to \mathit{List}~\mathit{IO}~\mathit{Char} \\
  \begin{array}{@{}l@{\hspace{0.2em}}l}
    \mathit{hGetContents}~h = \mathsf{List}~(\kw{do} & \mathit{isEOF} \leftarrow \mathit{hIsEOF}~h \\
    & \kw{if}~\mathit{isEOF}~\kw{then}~\mathit{return}~\mathsf{Nil} \\
    & \kw{else}~\kw{do}~
    \begin{array}[t]{@{}l}
      c \leftarrow \mathit{hGetChar}~h \\
      \mathit{return}~(\mathsf{Cons}~c~(\mathit{hGetContents}~h)))
    \end{array}
  \end{array}
\end{array}
\end{displaymath}
By using the $\mathit{List}~\mathit{IO}~\mathit{Char}$ datatype, we
have made the possibility of effects between the elements of the list
explicit. Therefore, the problems we identified above with implicit
interleaving are solved: input/output failures are reported within the
scope of $\mathit{IO}$ actions, and we have access to the
$\mathit{IO}$ monad to explicitly close the file.

The Haskell community
%\todo{link to Hackage}
has also defined many other datatypes that
capture the interleaving of effects with pure data, in order to make
explicit the interleaving implicit in the $\mathit{hGetContents}$
function. One of the earliest was Kiselyov's Iteratees
\cite{kiselyov12iteratees}. In essence, Iteratees are descriptions of
functions that alternate reading from some input with effects in some
monad, eventually yielding some output. This can be described by the
following datatype, which follows the same pattern of mutual recursion
as the $\mathit{List}~m~a$ datatype declaration:
\begin{displaymath}
  \begin{array}{ll}
    \kw{data}~\mathit{Reader'}~m~a~b
    &
    \kw{newtype}~\mathit{Reader}~m~a~b = 
    \\
    \quad
    \begin{array}[t]{c@{\hspace{0.5em}}l}
      = & \mathsf{Input}~(\mathit{Maybe}~a \to \mathit{Reader}~m~a~b) \\
      | & \mathsf{Yield}~b
    \end{array}
    &
    \quad \mathsf{Reader}~(m~(\mathit{Reader'}~m~a~b))
  \end{array}
\end{displaymath}
A value of type $\mathit{Reader}~m~a~b$ is some effect described by
the monad $m$, yielding either a result of type $b$, or a request for
input. As Kiselyov demonstrates, the fact that values of type
$\mathit{Reader}~m~a~b$ abstract the source of the data that they read
is extremely powerful: different constructions allow values of type
$\mathit{Reader}~m~a~b$ to be chained together, or connected to actual
input/output devices, all while retaining the ability to perform
concrete effects in the monad $m$.  Kiselyov treats the
$\mathit{Reader}~m~a~b$ type in isolation. In this article, we show
that it can be regarded as an instance of the general construction of
the coproduct of a free monad and an arbitrary monad. This
construction builds on the general foundation of initial
$f$-and-$m$-algebras.

\subsection{The content of this paper}

We aim to make this paper relatively self-contained, so we include the
necessary background to enable the reader to follow our proofs and
definitions. The structure of the remainder of the paper is as
follows:
\begin{itemize}
\item In \autoref{sec:f-algebras}, we recall the standard definitions
  of $f$-algebra and initial $f$-algebras, in a functional programming
  context. We highlight the proof principle associated with initial
  $f$-algebras (\proofprinref{pp:initial-alg}), and demonstrate that the
  initial $f$-algebra abstraction can be thought of as an abstract
  interface for programming and reasoning against.
\item We introduce our main running example of list append and its
  associativity property in \autoref{sec:pure-append}. In this
  section, we make use of the initial $f$-algebra methodology for pure
  datatypes to define list append, and also to show how
  \proofprinref{pp:initial-alg} is used to prove its associativity
  property.
\item In \autoref{sec:monads}, we recall the definition of monads, and
  briefly discuss the work of Fokkinga \cite{fokkinga94monadic} and
  Pardo \cite{pardo04combining} on recursion schemes in the presence
  of effects. As we note there, their work covers the case of
  effectful computations on pure data, whereas we wish to consider
  computations on effectful data.
\item To motivate the use of $f$-and-$m$-algebras, in
  \autoref{sec:direct-eappend} we attempt to define and prove
  associative the append function for effectful lists directly from
  \proofprinref{pp:initial-alg}. This turns out to be unnecessarily
  complicated and loses the direct simplicity of the proof in the pure
  case.
\item In \autoref{sec:f-and-m-algebras}, we present the definition of
  $f$-and-$m$-algebras, and highlight the associated proof principle
  (\proofprinref{pp:initial-f-m-alg}). Initial $f$-and-$m$-algebras
  raise our level of abstraction by separating the concerns of pure
  data and effectful computation. We demonstrate the usefulness of
  this separation in \autoref{sec:f-and-m-append}, where we revisit
  the definition of list append on effectful lists, and its
  associativity property. Using initial algebra semantics for
  $f$-and-$m$-algebras, we are able to reuse much of the
  definition and proof from the pure case in
  \autoref{sec:pure-append}, and the additional work that we need to
  carry to deal with effects is minimal.
\item In \autoref{sec:impl-f-and-m}, we show that the construction of
  initial $f$-and-$m$-algebras can be reduced to initial $(f \circ
  m)$-algebras. Consequently, we are able to give a generic
  construction of initial $f$-and-$m$-algebras for arbirary functors
  $f$ and monads $m$.
\item Finally, in \autoref{sec:coproducts-with-free-monads}, we
  present an extended example of the use of initial
  $f$-and-$m$-algebras. We reconstruct a result of Hyland, Plotkin and
  Power on the construction of coproducts of free monads with
  arbitrary monads, using $f$-and-$m$-algebras. This construction has
  practical interest, in that it provides a general construction of
  monads that interleave abstract and concrete commands, as seen in
  the $\mathit{Reader}~m~a~b$ monad in the previous section. The monad
  coproduct structure further highlights the central theme of this
  paper: the separation of concerns of dealing with pure data and
  effects.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background: initial $f$-algebras}
\label{sec:f-algebras}

Initial $f$-and-$m$-algebras build upon the basic foundation of
initial $f$-algebras. We recall the definition of initial $f$-algebras
in this section, derive the accompanying definitional and proof
principles. We will make use of the basic definitions of the
polymorphic identity function $\mathit{id} = \lambda x.~x$ and
function composition $g \circ h = \lambda x.~g~(h~x)$.

\subsection{Basic definitions}

The initial $f$-algebra methodology uses functors $f$ to describe the
individual ``layers'' of recursive datatypes.
Formally, functors are defined as follows:
\begin{definition}\label{defn:functor}
  A \emph{functor} is a pair $(f, \mathit{fmap}_f)$ of a type operator
  $f$ and a function $\mathit{fmap}_f$ of type:
  \begin{displaymath}
    \mathit{fmap}_f :: (a \to b) \to f~a \to f~b
  \end{displaymath}
  such that $\mathit{fmap}_f$ preserves the identity function and
  composition:
  \begin{align}
    \label{eq:fmap-id}
    \mathit{fmap}_f~\mathit{id} & = \mathit{id} \\
    \label{eq:fmap-comp}
    \mathit{fmap}_f~(g \circ h) & = \mathit{fmap}_f~g \circ \mathit{fmap}_f~h
  \end{align}
\end{definition}

In Haskell, the fact that a type operator $f$ has an associated
$\mathit{fmap}_f$ is usually expressed by declaring that $f$ is a
member of the $\mathit{Functor}$ typeclass:
\begin{displaymath}
  \begin{array}{l}
    \kw{class}~\mathit{Functor}~f~\kw{where} \\
    \quad \mathit{fmap} :: (a \to b) \to f~a \to f~b
  \end{array}
\end{displaymath}
It is left to the programmer to verify that the identity and
composition laws are satisfied.
%\todo{link back to this when we talk about EM-algs}
The use of typeclasses to represent functors allows
the programmer to just write $\mathit{fmap}$ and let the type checker
infer which $f$'s associated $\mathit{fmap}$ was intended. However, in
the interest of clarity, we shall always use a subscript on
$\mathit{fmap}$ to indicate which type operator is intended.

An $f$-algebra for a given functor $f$ is a way of describing an
action for each layer in an inductive data structure. Formally,
$f$-algebras are defined as follows:
\begin{definition}
  An \emph{$f$-algebra} is a pair $(a, \mathit{fAlgebra}_a)$ of a
  \emph{carrier type} $a$ and a \emph{structure map}
  $\mathit{fAlgebra}_a :: f~a \to a$.
\end{definition}
Given a pair of $f$-algebras, there is also the concept of a
homomorphism between them:
\begin{definition}
  Given a pair of $f$-algebras $(a,\mathit{fAlgebra}_a)$ and $(b,
  \mathit{fAlgebra}_b)$, an \emph{$f$-algebra homomorphism} between them is a
  function $h :: a \to b$ such that
  \begin{equation}
    \label{eq:falgebra-homomorphism}
    h \circ \mathit{fAlgebra}_a = \mathit{fAlgebra}_b \circ \mathit{fmap}_f~h
  \end{equation}
\end{definition}

\begin{definition}
  An \emph{initial $f$-algebra} is an $f$-algebra $(\mu f,
  \mathit{construct})$ such that for any $f$-algebra $(a,
  \mathit{fAlgebra}_a)$, there exists a unique $f$-algebra
  homomorphism $\fold{\mathit{fAlgebra}_a} :: \mu f \to a$.
\end{definition}

The requirement that an initial $f$-algebra always has an $f$-algebra
homomorphism to any $f$-algebra allows us to define functions on the
datatypes represented by carriers $\mu f$ of initial $f$-algebras. The
uniqueness requirement yields the following proof principle for
functions defined on initial $f$-algebras.

\begin{proofprinciple}[Initial $f$-Algebras]\label{pp:initial-alg}
  Suppose that $(\mu f, \mathit{construct})$ is an initial $f$-algebra.

  Let $(a, \mathit{fAlgebra})$ be an $f$-algebra, and $g :: \mu~f \to
  a$ be a function. To prove an equation
  \begin{displaymath}
    \fold{\mathit{fAlgebra}} = g,
  \end{displaymath}
  it suffices to show that $g$ is an $f$-algebra homomorphism:
  \begin{displaymath}
    g \circ \mathit{construct} = \mathit{fAlgebra} \circ \mathit{fmap}_f~g.
  \end{displaymath}
\end{proofprinciple}

%\todo{Refer to induction?}

\subsection{Examples of initial $f$-algebras}
\label{sec:example-initial-f}

The usefulness of the initial $f$-algebra abstraction for functional
programming lies in the fact that we can directly implement initial
$f$-algebras in functional programming languages. We give two examples
of implementations of initial $f$-algebras. The first example shows
that standard recursively defined Haskell datatypes can be retrofitted
with the initial $f$-algebra structure. The second example shows that
it is possible, in Haskell, to construct an initial $f$-algebra for
any functor $(f,\mathit{fmap_f})$.

\begin{example}
  The functor $\mathit{ListF}~a$ describes the individual layers of a
  list:
  \begin{displaymath}
    \begin{array}{@{}l@{\hspace{3em}}l}
      \begin{array}{l}
        \kw{data}~\mathit{ListF}~a~x \\
        \quad
        \begin{array}{c@{\hspace{0.3em}}l}
          = & \mathsf{Nil} \\
          | & \mathsf{Cons}~a~x
        \end{array}
      \end{array}
      &
      \begin{array}{l}
        \mathit{fmap}_{\mathit{ListF}~a} :: (x \to y) \to \mathit{ListF}~a~x \to \mathit{ListF}~a~y \\
        \begin{array}{@{}l@{\hspace{0.3em}}l@{\hspace{0.3em}}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
          \mathit{fmap}_{\mathit{ListF}~a}&g&\mathsf{Nil} &=& \mathsf{Nil} \\
          \mathit{fmap}_{\mathit{ListF}~a}&g&(\mathsf{Cons}~a~x) &=& \mathsf{Cons}~a~(g~x)
        \end{array}
      \end{array}
    \end{array}
  \end{displaymath}
  The following definitions witness that the standard Haskell list datatype
  $[a]$ is the carrier of an initial $\mathit{ListF}~a$ algebra:
  \begin{displaymath}
    \begin{array}{l}
      \mathit{construct} :: \mathit{ListF}~a~[a] \to [a] \\
      \begin{array}{@{}l@{\hspace{0.3em}}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
        \mathit{construct}&\mathsf{Nil} &=& [~] \\
        \mathit{construct}&(\mathsf{Cons}~a~\mathit{xs}) &=& a : \mathit{xs}
      \end{array}
    \end{array}
  \end{displaymath}
  and
  \begin{displaymath}
    \begin{array}{l}
      \fold{-} :: (\mathit{ListF}~a~b \to b) \to [a] \to b \\
      \begin{array}{@{}l@{\hspace{0.3em}}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
        \fold{\mathit{fAlgebra}}&[~]&=&\mathit{fAlgebra}~\mathsf{Nil} \\
        \fold{\mathit{fAlgebra}}&(a : \mathit{xs})&=&\mathit{fAlgebra}~(\mathsf{Cons}~a~(\fold{\mathit{fAlgebra}}~\mathit{xs}))
      \end{array}
    \end{array}
  \end{displaymath}
\end{example}

\begin{example}
  We can implement the carrier of an initial $f$-algebra for an arbitrary
  functor $(f, \mathit{fmap}_f)$ as a recursive datatype:
  \begin{displaymath}
    \kw{data}~\mathit{Mu}~f = \mathsf{In}~\{ \mathit{unIn} :: f~(\mathit{Mu}~f) \}
  \end{displaymath}
  We have used Haskell's record definition syntax to implicitly define
  a function $\mathit{unIn} :: \mathit{Mu}~f \to f~(\mathit{Mu}~f)$
  that is the inverse of the value constructor $\mathsf{In}$.  The
  $f$-algebra structure map is defined as the value
  constructor $\mathsf{In}$:
  \begin{displaymath}
    \begin{array}{l}
      \mathit{construct} :: f~(\mathit{Mu}~f) \to \mathit{Mu}~f \\
      \mathit{construct} = \mathsf{In}
    \end{array}
  \end{displaymath}
  and the $f$-algebra homomorphisms out of $\mathit{Mu}~f$ are defined
  in terms of the functor structure $\mathit{fmap}_f$ and Haskell's
  general recursion:
  \begin{displaymath}
    \begin{array}{l}
      \fold{-} :: \mathit{Functor}~f \Rightarrow (f~a \to a) \to \mathit{Mu}~f \to a \\
      \fold{\mathit{fAlgebra}} = \mathit{fAlgebra} \circ \mathit{fmap}_f~\fold{\mathit{fAlgebra}} \circ \mathit{unIn}
    \end{array}
  \end{displaymath}
  This construction has been called ``two-level types''
  \cite{sheard04twolevel}, due to the separation between the functor
  $f$ and the recursive datatype $\mathit{Mu}$.
\end{example}

These two examples demonstrate that initial algebras for a given
functor are not unique: the types $[a]$ and
$\mathit{Mu}~(\mathit{ListF}~a)$ are not equal, but they are both
initial $(\mathit{ListF}~a)$-algebras. Therefore, we regard the
initial $f$-algebra abstraction as an interface to program against,
rather than thinking of specific implementations such as
$\mathit{Mu}~f$. Note that it is possible to prove that any two
initial $f$-algebras are isomorphic, by using the initial algebra
property to define the translations between, and
\proofprinref{pp:initial-alg} to prove that the translations are
mutually inverse. This isomorphism result is known as Lambek's lemma
\cite{LAMBEK68}.

\section{List append I: pure lists}
\label{sec:pure-append}

We now introduce our running example of list append and its
associativity property. In this section, we use an initial
$(\mathit{ListF}~a)$-algebra and \proofprinref{pp:initial-alg} to
define and prove associative the append function on pure lists. In
\autoref{sec:direct-eappend} we attempt the same example in a setting
with interleaved effects, using the initial $f$-algebra technique, and
see that direct use of initial $f$-algebras makes the definition and
proof unnecessarily complicated. In \autoref{sec:f-and-m-algebras}, we
use $f$-and-$m$-algebras to simplify the definition and proof, and
show that this lets us reuse much of the definition and proof that we
give in this section.

The definition and proof that we present here are standard and have
appeared many times in the literature. We present them in some detail
in order to use them as a reference when we cover the analogous proof
for append for lists interleaved with effects.

We program and reason against the abstract interface of initial
algebras. Hence we assume that an initial $(\mathit{ListF}~a)$-algebra
$(\mu(\mathit{ListF}~a), \mathit{construct})$ exists, and we write
$\fold{-}$ for the unique homomorphism induced by initiality. We can
define $\mathit{append}$ in terms of $\fold{-}$ as:
\begin{displaymath}
  \begin{array}{l}
    \mathit{append} :: \mu(\mathit{ListF}~a) \to \mu(\mathit{ListF}~a) \to \mu(\mathit{ListF}~a) \\
    \mathit{append}~\mathit{xs}~\mathit{ys} = \fold{\mathit{fAlgebra}}~\mathit{xs} \\
    \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
      \kw{where} & \mathit{fAlgebra}~\mathsf{Nil} &=& \mathit{ys} \\
                     & \mathit{fAlgebra}~(\mathsf{Cons}~a~\mathit{xs}) &=& \mathit{construct}~(\mathsf{Cons}~a~\mathit{xs})
    \end{array}
  \end{array}
\end{displaymath}
Immediately from the definition of $\mathit{append}$ we know that it
is a $(\mathit{ListF}~a)$-algebra homomorphism because it is defined
in terms of $\fold{-}$. Unfolding the definitions shows that the
following two equational properties of $\mathit{append}$ hold. These
tell us how it operates on lists of the form
$\mathit{construct}~\mathsf{Nil}$ and
$\mathit{construct}~(\mathsf{Cons}~a~\mathit{xs})$. We have:
\begin{align}
  \label{eq:append-nil}
  \mathit{append}~(\mathit{construct}~\mathsf{Nil})~\mathit{ys} & = \mathit{ys} \\
  \label{eq:append-cons}
  \mathit{append}~(\mathit{construct}~(\mathsf{Cons}~a~\mathit{xs}))~\mathit{ys} & = \mathit{construct}~(\mathsf{Cons}~a~(\mathit{append}~\mathit{xs}~\mathit{ys}))
\end{align}
We now make use of these properties, and
\proofprinref{pp:initial-alg}, to prove associativity:

\begin{theorem}\label{thm:append-assoc}
  For all $\mathit{xs}, \mathit{ys}, \mathit{zs} :: \mu(\mathit{ListF}~a)$,
  \begin{displaymath}
    \mathit{append}~\mathit{xs}~(\mathit{append}~\mathit{ys}~\mathit{zs}) = \mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs}
  \end{displaymath}
\end{theorem}

\begin{proof*}
  The function $\mathit{append}$ is defined in terms of the initial
  algebra property of $\mu(\mathit{ListF}~a)$, we use
  \proofprinref{pp:initial-alg} to prove the equation:
  \begin{displaymath}
    \fold{\mathit{fAlgebra}}~\mathit{xs} = \mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs}
  \end{displaymath}
  In this instantiation of \proofprinref{pp:initial-alg}, $g = \lambda
  \mathit{xs}.~\mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs}$,
  and:
  \begin{align}
    \label{eq:append-fAlgebra-nil}
    \mathit{fAlgebra}~\mathsf{Nil} &= \mathit{append}~\mathit{ys}~\mathit{zs} \\
    \label{eq:append-fAlgebra-cons}
    \mathit{fAlgebra}~(\mathsf{Cons}~a~\mathit{xs}) &= \mathit{construct}~(\mathsf{Cons}~a~\mathit{xs})
  \end{align}
  Thus we need to prove that for all $x ::
  \mathit{ListF}~a~(\mu(\mathit{ListF}~a))$,
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{append}~(\mathit{append}~(\mathit{construct}~x)~\mathit{ys})~\mathit{zs}\\
      =&\mathit{fAlgebra}~(\mathit{fmap}_{\mathit{ListF}~a}~(\lambda \mathit{xs}.~\mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs})~x)
    \end{array}
  \end{displaymath}
  There are two cases to consider, depending on whether $x =
  \mathsf{Nil}$ or $x = \mathsf{Cons}~a~\mathit{xs}$. In the first
  case, we reason as follows:
  \begin{displaymath}
    \begin{array}{cl}
      & \mathit{append}~(\mathit{append}~(\mathit{construct}~\mathsf{Nil})~\mathit{ys})~\mathit{zs}\\
      =&\eqAnnotation{\autoref{eq:append-nil}} \\
      & \mathit{append}~\mathit{ys}~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{fAlgebra}$ (\autoref{eq:append-fAlgebra-nil})} \\
      & \mathit{fAlgebra}~\mathsf{Nil} \\
      =&\eqAnnotation{definition of $\mathit{fmap}_{\mathit{ListF}~a}$} \\
      & \mathit{fAlgebra}~(\mathit{fmap}_{\mathit{ListF}~a}~(\lambda \mathit{xs}.~\mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs})~\mathsf{Nil})
    \end{array}
  \end{displaymath}
  The other possibility is that $x = \mathsf{Cons}~a~\mathit{xs}$, and
  we reason as follows:
  \begin{displaymath}
    \begin{array}{cl}
      & \mathit{append}~(\mathit{append}~(\mathit{construct}~(\mathsf{Cons}~a~\mathit{xs}))~\mathit{ys})~\mathit{zs}\\
      =&\eqAnnotation{\autoref{eq:append-cons}} \\
      & \mathit{append}~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{append}~\mathit{xs}~\mathit{ys})))~\mathit{zs}\\
      =&\eqAnnotation{\autoref{eq:append-cons}} \\
      & \mathit{construct}~(\mathsf{Cons}~a~(\mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs}))\\
      =&\eqAnnotation{definition of $\mathit{fAlgebra}$ (\autoref{eq:append-fAlgebra-cons})} \\
      & \mathit{fAlgebra}~(\mathsf{Cons}~a~(\mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs}))\\
      =&\eqAnnotation{definition of $\mathit{fmap}_{\mathit{ListF}~a}$} \\
      & \mathit{fAlgebra}~(\mathit{fmap}_{\mathit{ListF}~a}~(\lambda \mathit{xs}.~\mathit{append}~(\mathit{append}~\mathit{xs}~\mathit{ys})~\mathit{zs})~(\mathsf{Cons}~a~\mathit{xs})) \mathproofbox\\
    \end{array}
  \end{displaymath}
\end{proof*}

Thus the proof that $\mathit{append}$ is associative is relatively
straightforward, using \proofprinref{pp:initial-alg}. We shall see
below, in \autoref{sec:direct-eappend}, that attempting to use
\proofprinref{pp:initial-alg} again to reason about lists interleaved
with effects leads to a more complicated proof that mingles the
reasoning above with reasoning about monadic effects. We then make use
of $f$-and-$m$-algebras in \autoref{sec:f-and-m-algebras} to prove the
same property for lists interleaved with effects, and show that we are
able to reuse the core of the above proof.
%\todo{Make sure this is general}

\section{Background: monadic effects and monadic recursion schemes}
\label{sec:monads}

As is standard in Haskell programming, we describe effectful
computations in terms of monads \cite{moggi91notions,
  peytonjones93imperative}. In order to keep this article self
contained, we recall the definition of monad here. We also briefly
examine prior work by Fokkinga, and by Pardo, on effectful recursive
programs on pure data.

\subsection{Monadic Effects}

We have opted to use the ``categorical'' definition of monad in terms
of a $\mathit{join}$ (or \emph{multiplication}) operation, rather than the
Kleisli-triple presentation with a bind operation ($\mbind$) that is
more standard in Haskell programming. For our purposes, the
categorical definition is more convenient for equational
reasoning. Standard references such as the lecture notes by Benton,
Hughes and Moggi \cite{benton00monads} discuss the translations
between the two presentations.

\begin{definition}\label{defn:monad}
  A monad is a quadruple $(m, \mathit{fmap}_m, \mathit{return}_m,
  \mathit{join}_m)$ of a type constructor $m$, and three functions:
  \begin{displaymath}
    \begin{array}{r@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
      \mathit{fmap}_m   & :: & (a \to b) \to m~a \to m~b \\
      \mathit{return}_m & :: & a \to m~a \\
      \mathit{join}_m   & :: & m~(m~a) \to m~a
    \end{array}
  \end{displaymath}
  such that the pair $(m, \mathit{fmap}_m)$ is a functor
  (\defref{defn:functor}), and the following properties are satisfied:
  \begin{align}
    \label{eq:monad-join-return}
    \mathit{join}_m \circ \mathit{return}_m & = \mathit{id} \\
    \label{eq:monad-join-fmap-return}
    \mathit{join}_m \circ \mathit{fmap}_m~\mathit{return}_m & = \mathit{id} \\
    \label{eq:monad-join-join}
    \mathit{join}_m \circ \mathit{fmap}_m~\mathit{join}_m & = \mathit{join}_m \circ \mathit{join}_m
  \end{align}
  and also the naturality laws:
  \begin{align}
    \label{eq:monad-return-natural}
    \mathit{return}_m \circ f & = \mathit{fmap}_m~f \circ \mathit{return}_m \\
    \label{eq:monad-join-natural}
    \mathit{join}_m \circ \mathit{fmap}_m~(\mathit{fmap}_m~f) & = \mathit{fmap}_m~f \circ \mathit{join}_m
  \end{align}
\end{definition}

As with functors, monads in Haskell are usually represented in terms of
the $\textit{Monad}$ typeclass. Again, for this article, we will
always use subscripts on $\mathit{return}_m$ and $\mathit{join}_m$ to
disambiguate which monad is being referred to, instead of leaving it
to the reader to infer.

Finally in this short recap of monads, we recall the definition of a
\emph{monad morphism} between a pair of monads. Monad morphisms
represent structure preserving maps between monads. We will use monad
morphisms in our extended example of the use of $f$-and-$m$-algebras
to construct the coproduct of two monads in
\autoref{sec:coproducts-with-free-monads}.

\begin{definition}
  Let $(m_1, \mathit{fmap_{m_1}}, \mathit{return}_{m_1},
  \mathit{join_{m_1}})$ and $(m_2, \mathit{fmap_{m_1}},
  \mathit{return}_{m_2}, \mathit{join}_{m_2})$ be a pair of monads. A
  \emph{monad morphism} between them is a function $h :: m_1~a \to
  m_2~a$ such that:
  \begin{align}
    \label{eq:monad-mor-natural}
    h \circ \mathit{fmap}_{m_1}~g & = \mathit{fmap}_{m_2}~g \circ h \\
    \label{eq:monad-mor-return}
    h \circ \mathit{return}_{m_1} & = \mathit{return}_{m_2} \\
    \label{eq:monad-mor-join}
    h \circ \mathit{join}_{m_1} & = \mathit{join}_{m_2} \circ h \circ \mathit{fmap}_{m_1}~h
  \end{align}
\end{definition}

\subsection{Monadic Recursion Schemes}

The initial $f$-algebra methodology has been extended to effectful
computation on pure data by Fokkinga \cite{fokkinga94monadic} and
Pardo \cite{pardo04combining}. The generic recursion combinator they
use for effectful recursive computations has the following type:
\begin{displaymath}
  \fold{-}_m : (f~a \to m~a) \to \mu f \to m~a
\end{displaymath}
where they also make the implicit assumption that there is a
\emph{distributive law} $d :: f~(m~a) \to m~(f~a)$ that describes how
effects percolate through pure data. Fokkinga and Pardo separately
derive theories and proof principles for effectful structural
recursion over \emph{pure} data. By contrast, in this paper we wish to
explore computation and reasoning with \emph{effectful} data, where
data and effects are interleaved.

% We have already noted that are several benefits to defining functions
% in terms of higher-order recursion combinators like
% $\mathit{foldr}$. Moreover, it would be nice if there were a general
% theory comparable to initial $f$-algebras for programming and
% reasoning about functions defined on datatypes like
% $\mathit{List}~m~a$ and $\mathit{Reader}~m~a$.


\section{List append II: lists with interleaved effects, via $f$-algebras}
\label{sec:direct-eappend}

Given the success of initial $f$-algebras for defining and reasoning
about programs that operate on pure datatypes, it seems reasonable
that they might extend to programming and reasoning about programs
that operate on effectful datatypes like $\mathit{List}~m~a$ and
$\mathit{Reader}~m~a~b$. As we shall see, it is possible to use
initial $f$-algebras for reasoning about programs on effectful
datatypes, but the proofs become unnecessarily complicated. We
demonstrate this through an extension of the list append example from
\autoref{sec:pure-append} to the case of lists with interleaved
effects.

Our presentation is parameteric in the kind of effects that
are interleaved with the list. We merely assume that they can be
described by some monad $(m, \mathit{fmap_m}, \mathit{return_m},
\mathit{join_m})$.

By inspecting the auxillary declarations of $\mathit{List'}~m~a$ and
$\mathit{Reader'}~m~a~b$, and comparing them to the examples of
initial $f$-algebras that we presented in the
\autoref{sec:f-algebras}, we can see that they are themselves carriers
of initial $(f \circ m)$-algebras, where $f$ is an appropriate functor
and $\circ$ denotes functor composition. For example,
$\mathit{List}~m~a$ is isomorphic to $m~(\mu (\mathit{ListF}~a \circ
m))$, where $\mu (\mathit{ListF}~a \circ m)$ is the carrier of some
initial $(\mathit{ListF}~a \circ m)$-algebra.

Equipped with this observation, we can proceed with adapting the
definition of $\mathit{append}$ that we gave in
\autoref{sec:pure-append} to the setting of lists interleaved with
effects. As above, we program and reason against the abstract
interface of initial algebras. We assume that an initial
$(\mathit{ListF}~a \circ m)$-algebra $(\mu(\mathit{ListF}~a \circ m),
\mathit{construct})$ exists, and we write $\fold{-}$ for the unique
homomorphism induced by initiality. We now define $\mathit{eAppend}$
(``$\mathit{e}$'' for effectful) by:
\begin{displaymath}
  \begin{array}{l}
    \mathit{eAppend} :: m~(\mu (\mathit{ListF}~a \circ m)) \to m~(\mu (\mathit{ListF}~a \circ m)) \to m~(\mu (\mathit{ListF}~a \circ m)) \\
    \mathit{eAppend}~\mathit{xs}~\mathit{ys} = \mathit{join}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra}}~\mathit{xs}) \\
    \begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
      \textbf{where} & \mathit{fAlgebra}~\mathsf{Nil} &=& \mathit{ys} \\
                     & \mathit{fAlgebra}~(\mathsf{Cons}~a~\mathit{xs}) &=& \mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{join}_m~\mathit{xs})))
    \end{array}
  \end{array}
\end{displaymath}
This definition bears a slight resemblance to the definition of
$\mathit{append}$ above, but we have had to insert uses of the monadic
structure $\mathit{return_m}$, $\mathit{join_m}$ and $\mathit{fmap_m}$
to deal with the management of effects. Thus we have had to
intermingle the effectful parts of the definition with the pure
parts. This is a result of the fact that the initial $f$-algebra
abstraction is unaware of the presence of effects.

As we did for $\mathit{append}$ in \autoref{eq:append-nil} and
\autoref{eq:append-cons} above, we can derive two properties of
$\mathit{eAppend}$ that tell us how it acts on the two list
constructors:
\begin{equation}
  \label{eq:eappend-direct-nil}
  \mathit{eAppend}~(\mathit{return}_m~(\mathit{construct}~\mathsf{Nil}))~\mathit{ys} = \mathit{ys}
\end{equation}
and
\begin{equation}\label{eq:eappend-direct-cons}
  \begin{array}{cl}
    & \mathit{eAppend}~(\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~\mathit{xs})))~\mathit{ys} \\ 
    =&\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})))
  \end{array}
\end{equation}
We note that the derivations of these equations involve more work
than their counterparts for $\mathit{append}$. In particular, we are
forced to spend time shuffling the $\mathit{return_m}$,
$\mathit{join_m}$ and $\mathit{fmap_m}$ around in order to apply the
monad laws. Evidently, if we were to always use initial $f$-algebras
to define functions on datatypes with interleaved effects, we would be
repeating this work over again. Moreover, as we shall see in the proof
of \thmref{thm:direct-eappend-assoc} below, we cannot make direct use
of \autoref{eq:eappend-direct-nil}, because we are forced to unfold
the definition of $\mathit{eAppend}$ too early.

\begin{theorem}\label{thm:direct-eappend-assoc}
  For all $\mathit{xs}, \mathit{ys}, \mathit{zs} :: m~(\mu (\mathit{ListF}~a \circ m))$,
  \begin{displaymath}
    \mathit{eAppend}~\mathit{xs}~(\mathit{eAppend}~\mathit{ys}~\mathit{zs}) = \mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs}
  \end{displaymath}
\end{theorem}

\begin{proof*}
  We will eventually be able to use \proofprinref{pp:initial-alg}, but
  first we must rearrange both sides of the equation to be of a
  suitable form. For this proof, we adopt the notation
  $\mathit{fAlgebra}_l$ to denote an instance of the
  $\mathit{fAlgebra}$ function defined in the body of
  $\mathit{eAppend}$ with the free variable $\mathit{ys}$ replaced by
  $l$.

  The left hand side of the equation to be proved is equal to:
  \begin{displaymath}
    \begin{array}{cl}
       &\mathit{eAppend}~\mathit{xs}~(\mathit{eAppend}~\mathit{ys}~\mathit{zs}) \\
       =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
       &\mathit{join_m}~(\mathit{fmap_m}~\fold{\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}}~\mathit{xs})
    \end{array}
  \end{displaymath}
  The right hand side of the equation requires a little more work:
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
      &\mathit{eAppend}~(\mathit{join}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra}_{\mathit{ys}}}~\mathit{xs}))~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
      &\mathit{join}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{zs}}}~(\mathit{join}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra}_{\mathit{ys}}}~\mathit{xs}))) \\
      =&\eqAnnotation{naturality of $\mathit{join_m}$ (\autoref{eq:monad-join-natural})} \\
      &\mathit{join}_m~(\mathit{join}_m~(\mathit{fmap}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{zs}}})~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs}))) \\
      =&\eqAnnotation{monad law: 
%$\mathit{join_m} \circ \mathit{join_m} = \mathit{join_m} \circ \mathit{fmap_m}~\mathit{join_m}$ 
\autoref{eq:monad-join-join}} \\
      &\mathit{join_m}~(\mathit{fmap_m}~\mathit{join_m}~(\mathit{fmap}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{zs}}})~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs}))) \\
      =&\eqAnnotation{$\mathit{fmap_m}$ preserves composition (\autoref{eq:fmap-comp})} \\
      &\mathit{join_m}~(\mathit{fmap_m}~(\mathit{join_m} \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra_{zs}}} \circ \fold{\mathit{fAlgebra_{ys}}})~\mathit{xs}) \\
      =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
      &\mathit{join_m}~(\mathit{fmap_m}~((\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \fold{\mathit{fAlgebra_{ys}}})~\mathit{xs})
    \end{array}
  \end{displaymath}
  Looking at the final lines of these two chains of equations, we see
  that the problem reduces to proving the following equation:
  \begin{displaymath}
    \fold{\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}} = (\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \fold{\mathit{fAlgebra_{ys}}}
  \end{displaymath}
  To prove this equation, we use \proofprinref{pp:initial-alg}, which
  reduces the problem to proving the following equation, for all $x ::
  \mathit{ListF}~a~(m~(\mu(\mathit{ListF}~a \circ m)))$:
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{eAppend}~(\fold{\mathit{fAlgebra_{ys}}}~(\mathit{construct}~x))~\mathit{zs} \\
      =& \mathit{fAlgebra}_{\mathit{eAppend}~\mathit{xs}~\mathit{ys}}~(\mathit{fmap}_{\mathit{ListF}~a}~(\mathit{fmap}_m~((\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \fold{\mathit{fAlgebra_{ys}}}))~x)
    \end{array}
  \end{displaymath}
  There are two cases to consider, depending on whether $x =
  \mathsf{Nil}$ or $x = \mathsf{Cons}~a~\mathit{xs}$. In the first
  case, we reason as follows. Note that, we are unable to directly
  apply our knowledge of the effect of $\mathit{eAppend}$ on
  $\mathsf{Nil}$ (\autoref{eq:eappend-direct-nil}), unlike in the
  proof of \thmref{thm:append-assoc} where we could use
  \autoref{eq:append-nil}. This is because we had to unfold the
  definition of $\mathit{eAppend}$ in order to apply
  \proofprinref{pp:initial-alg}.
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{eAppend}~(\fold{\mathit{fAlgebra_{ys}}}~(\mathit{construct}~\mathsf{Nil}))~\mathit{zs} \\
      =&\eqAnnotation{$\fold{\mathit{fAlgebra_{ys}}}$ is a $(\mathit{ListF}~a \circ m)$-algebra homomorphism} \\
      &\mathit{eAppend}~(\mathit{fAlgebra_{ys}}~(\mathit{fmap}_{\mathit{ListF}~a}~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}})~\mathsf{Nil}))~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{fmap_{\mathit{ListF}~a}}$} \\
      &\mathit{eAppend}~(\mathit{fAlgebra_{ys}}~\mathsf{Nil})~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{fAlgebra_{ys}}$} \\
      &\mathit{eAppend}~\mathit{ys}~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}$} \\
      &\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}~\mathsf{Nil} \\
      =&\eqAnnotation{definition of $\mathit{fmap}_{\mathit{ListF}~a}$} \\
      &\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{xs}~\mathit{ys}}~(\mathit{fmap}_{\mathit{ListF}~a}~(\mathit{fmap}_m~((\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \fold{\mathit{fAlgebra_{ys}}}))~\mathsf{Nil})
    \end{array}
  \end{displaymath}
  In the second case, when $x = \mathsf{Cons}~a~\mathit{xs}$, we
  reason using the following steps:
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{eAppend}~(\fold{\mathit{fAlgebra_{ys}}}~(\mathit{construct}~(\mathsf{Cons}~a~\mathit{xs})))~\mathit{zs} \\
      =&\eqAnnotation{$\fold{\mathit{fAlgebra_{ys}}}$ is a $(\mathit{ListF}~a \circ m)$-algebra homomorphism} \\
      &\mathit{eAppend}~(\mathit{fAlgebra_{ys}}~(\mathit{fmap}_{\mathit{ListF}~a}~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}})~(\mathsf{Cons}~a~\mathit{xs})))~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{fmap_{\mathit{ListF}~a}}$} \\
      &\mathit{eAppend}~(\mathit{fAlgebra_{ys}}~(\mathsf{Cons}~a~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs})))~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{fAlgebra_{ys}}$} \\
      & \mathit{eAppend}~(\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{join}_m~(\mathit{fmap_m}~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs})))))~\mathit{zs} \\
      =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
      & \mathit{eAppend}~(\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{eAppend}~\mathit{xs}~\mathit{ys}))))~\mathit{zs} \\
      =&\eqAnnotation{\autoref{eq:eappend-direct-cons}} \\
      & \mathit{return_m}~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs}))) \\
      =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
      &\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~\\
      & \hspace{1cm}(\mathit{join_m}~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{zs}}}~(\mathit{join}_m~(\mathit{fmap_m}~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs})))))) \\
      =&\eqAnnotation{naturality of $\mathit{join_m}$ (\autoref{eq:monad-join-natural})} \\
      &\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~\\
      & \hspace{1cm}(\mathit{join_m}~(\mathit{join}_m~(\mathit{fmap}_m~(\mathit{fmap_m}~\fold{\mathit{fAlgebra_{zs}}})~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs})))))) \\
      =&\eqAnnotation{monad law: $\mathit{join_m} \circ \mathit{join_m} = \mathit{join_m} \circ \mathit{fmap}_m~\mathit{join_m}$ (\autoref{eq:monad-join-join})} \\
      &\mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~\\
      & \hspace{1cm}(\mathit{join_m}~(\mathit{fmap}_m~\mathit{join_m}~\\
      & \hspace{1.5cm}(\mathit{fmap}_m~(\mathit{fmap_m}~\fold{\mathit{fAlgebra_{zs}}})~(\mathit{fmap}_m~\fold{\mathit{fAlgebra_{ys}}}~\mathit{xs})))))) \\
      =&\eqAnnotation{$\mathit{fmap}_m$ preserves function composition (\autoref{eq:fmap-comp})} \\
      & \mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~\\
      & \hspace{1cm}(\mathit{join_m}~(\mathit{fmap}_m~(\mathit{join_m} \circ \mathit{fmap_m}~\fold{\mathit{fAlgebra_{zs}}} \circ \fold{\mathit{fAlgebra_{ys}}})~\mathit{xs})))) \\
      =&\eqAnnotation{definition of $\mathit{eAppend}$} \\
      & \mathit{return}_m~(\mathit{construct}~(\mathsf{Cons}~a~\\
      & \hspace{1cm}(\mathit{join_m}~(\mathit{fmap}_m~((\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \circ \fold{\mathit{fAlgebra_{ys}}})~\mathit{xs})))) \\
      =&\eqAnnotation{definition of $\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}$} \\
      &\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}~(\mathsf{Cons}~a~(\mathit{fmap}_m~((\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \fold{\mathit{fAlgebra_{ys}}})~\mathit{xs})) \\
    \end{array}
  \end{displaymath}
  \begin{displaymath}
    \begin{array}{cl}
      =&\eqAnnotation{definition of $\mathit{fmap}_{\mathit{ListF}~a}$} \\
      &\mathit{fAlgebra}_{\mathit{eAppend}~\mathit{ys}~\mathit{zs}}~\\
      & \hspace{1cm}(\mathit{fmap}_{\mathit{ListF}~a}~(\mathit{fmap}_m~((\lambda l.~\mathit{eAppend}~l~\mathit{zs}) \circ \fold{\mathit{fAlgebra_{ys}}}))~(\mathsf{Cons}~a~\mathit{xs})) \mathproofbox
    \end{array}
  \end{displaymath}
\end{proof*}

We identify the following problems with this proof:
\begin{itemize}
\item We had to perform a non-trivial number of rewriting steps in
  order to get ourselves to into a position in which we can apply
  \proofprinref{pp:initial-alg}. These steps are not specific to the
  $\mathit{eAppend}$ function, and will have to be re-done whenever we
  wish to use \proofprinref{pp:initial-alg} to prove a property of a
  function on data interleaved with effects.
\item We were forced to unfold the definition of $\mathit{eAppend}$
  multiple times in order to proceed with the calculation. As we noted
  during the proof, this unfolding prevented us from applying
  \autoref{eq:eappend-direct-nil} and instead we had to perform some
  of the same calculation steps again. For the same reason, in the
  $\mathsf{Cons}$ case, we were only able to apply
  \autoref{eq:eappend-direct-cons} once, unlike in the proof of
  \thmref{thm:append-assoc} where the analogous equation was applied
  twice. We also had to expand $\mathit{eAppend}$ again in order to
  rewrite the occurences of $\mathit{join_m}$ and $\mathit{fmap_m}$.
\end{itemize}
The definition and proof that we have given in this section
demonstrates that direct use of initial $f$-algebras provides us with
the wrong level of abstraction for dealing with datatypes that
interleave data and effects.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Separating data and effects with $f$-and-$m$-algebras}
\label{sec:f-and-m-algebras}

As we saw in the previous section, directly defining and proving
properties of functions on datatypes consisting of interleaved pure
and effectful information is possible, but tedious. We were not able
to build upon the definition and proof that we used in the
non-effectful case (\autoref{sec:pure-append}), and our equational
reasoning repeatedly broke layers of abstraction: we were forced to
unfold the definition $\mathit{eAppend}$ several times in the proof of
\thmref{thm:direct-eappend-assoc} in order to perform further
calculation.

To solve the problems we have identified with the direct use of
$f$-algebras, we use the concept of $f$-and-$m$-algebras, originally
introduced by Filinski and St\o{}vring \cite{filinski07inductive}, and
generalised to arbitrary functors by the current authors
\cite{atkey12fibrational}. As the name may imply, $f$-and-$m$-algebras
are simultaneously $f$-algebras and $m$-algebras. A twist is that the
$m$-algebra component must be an Eilenberg-Moore
algebra. Eilenberg-Moore algebra structure for a type $a$ describes
how to incorporate the effects of the monad $m$ into values of type
$a$.

\subsection{Eilenberg-Moore algebras}
\label{sec:eilenberg-moore-algebras}

Given a monad $(m, \mathit{fmap}_m, \mathit{return}_m,
\mathit{join}_m)$ (\defref{defn:monad}), an
$m$-Eilenberg-Moore-algebra is an $m$-algebra that also interacts well
with the structure of the monad:

\begin{definition}
  An \emph{$m$-Eilenberg-Moore algebra} consists of a pair
  $(a,\mathit{mAlgebra}_a)$ of a type $a$ and a function
  \begin{displaymath}
    \mathit{mAlgebra}_a :: m~a \to a
  \end{displaymath}
  such that the following two equations are satisfied:
  \begin{align}
    \label{eq:em-alg-return}
    \mathit{mAlgebra}_a \circ \mathit{return}_m & = \mathit{id} \\
    \label{eq:em-alg-join}
    \mathit{mAlgebra}_a \circ \mathit{join}_m & = \mathit{mAlgebra}_a \circ \mathit{fmap}_m~\mathit{mAlgebra}_a
  \end{align}
\end{definition}

Eilenberg-Moore algebras form a key piece of the theory of monads,
especially in their application to universal algebra. For a monad that
represents an algebraic theory (e.g., abelian groups), the collection
of all Eilenberg-Moore algebras for that monad are exactly the
structures supporting that algebraic theory. Mac Lane's book
\cite{maclane98} goes into further depth on this view of
Eilenberg-Moore algebras.

In terms of computational effects, an $m$-Eilenberg-Moore-algebra $(a,
\mathit{mAlgebra})$ represents a way of ``performing'' the effects of
the monad $m$ in the type $a$. For example, if we let the monad $m$ be the
error monad $\mathit{ErrorM}$:
\begin{displaymath}
  \begin{array}{ll}
    \begin{array}[t]{l}
      \kw{data}~\mathit{ErrorM}~a \\
      \quad
      \begin{array}{c@{\hspace{0.5em}}l}
        = & \mathsf{Ok}~a \\
        | & \mathsf{Error}~\mathit{String}
      \end{array}
    \end{array}
    &
    \begin{array}[t]{l}
      \begin{array}{@{}l@{\hspace{0.3em}}l@{\hspace{0.3em}}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
        \mathit{fmap_{ErrorM}}&g&(\mathsf{Ok}~a) &=& \mathsf{Ok}~(g~a) \\
        \mathit{fmap_{ErrorM}}&g&(\mathsf{Error}~\mathit{msg}) &=& \mathsf{Error}~\mathit{msg} \\
      \end{array} \\
      \\
      \mathit{return_{ErrorM}}~a = \mathsf{Ok}~a \\
      \\
      \begin{array}{@{}l@{\hspace{0.3em}}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
        \mathit{join_{ErrorM}}&(\mathsf{Ok}~(\mathsf{Ok}~a)) &=& \mathsf{Ok}~a \\
        \mathit{join_{ErrorM}}&(\mathsf{Ok}~(\mathsf{Error}~\mathit{msg})) &=& \mathsf{Error}~\mathit{msg} \\
        \mathit{join_{ErrorM}}&(\mathsf{Error}~\mathit{msg}) &=& \mathsf{Error}~\mathit{msg}
      \end{array}
    \end{array}
  \end{array}
\end{displaymath}
then we can define an $\mathit{ErrorM}$-Eilenberg-Moore-algebra with
carrier $\mathit{IO}~a$ as follows:
\begin{displaymath}
  \begin{array}{l}
    \mathit{mAlgebra} :: \mathit{ErrorM}~(\mathit{IO}~a) \to \mathit{IO}~a \\
    \begin{array}{@{}l@{\hspace{0.4em}}lcl}
      \mathit{mAlgebra}&(\mathsf{Ok}~\mathit{ioa}) & = & \mathit{ioa} \\
      \mathit{mAlgebra}&(\mathsf{Error}~\mathit{msg}) & = & \mathit{throw}~(\mathsf{ErrorCall}~\mathit{msg})
    \end{array}
  \end{array}
\end{displaymath}
The function $\mathit{throw}$ and the constructor $\mathsf{ErrorCall}$
are part of the standard $\mathit{Control.Exception}$ module. This
$\mathit{mAlgebra}$ propagates normal $\mathit{IO}$ actions, and
interprets errors using the exception throwing facilities of the
Haskell $\mathit{IO}$ monad.

The general pattern of $m$-Eilenberg-Moore-algebras with carriers that
are themselves constructed from monads has been studied by Filinski
under the name ``layered monads'' \cite{filinski99representing}. The
idea is that the presence of $m$-Eilenberg-Moore-algebras of the form
$m~(m'~a) \to m'~a$, for all $a$, capture the fact that the monad $m'$
can perform all the effects that the monad $m$ can, so we can say that
$m'$ is layered over $m$.

A particularly useful class of Eilenberg-Moore algebras for a given
monad $m$ is the class of \emph{free}
$m$-Eilenberg-Moore-algebras. The \emph{free} Eilenberg-Moore algebra
for an arbitrary type $a$ is given by $(m~a, \mathit{join}_m)$. In
terms of layered monads, this just states that the monad $m$ can be
layered over itself. We will make use of this construction below in
the proof of \thmref{thm:make-initial-f-and-m-alg} below.

% If we step back from considering specific monads, there are three
% generic ways of making Eilenberg-Moore algebras for a given monad $m$:
% \begin{enumerate}
% \item 
% \item Given an $m$-Eilenberg-Moore-algebra $(a, \mathit{mAlgebra}_a)$
%   and an arbitrary type $b$, we can construct the \emph{exponential}
%   $m$-Eilenberg-Moore algebra with carrier $b \to a$ and:
%   \begin{displaymath}
%     \begin{array}{l}
%       \mathit{mAlgebra}_{b \to a} :: m~(b \to a) \to (b \to a) \\
%       \mathit{mAlgebra}_{b \to a}~x~b = \mathit{mAlgebra}_a~(\mathit{fmap}_m~(\lambda f.~f~b)~x)
%     \end{array}
%   \end{displaymath}
%   % FIXME: forward ref here if we use it
% \item Given a pair of $m$-Eilenberg-Moore-algebras $(a,
%   \mathit{mAlgebra}_a)$ and $(b, \mathit{mAlgebra}_b)$, we can form
%   the \emph{product} $m$-Eilenberg-Moore-algebra with carrier $(a,b)$
%   and:
%   \begin{displaymath}
%     \begin{array}{l}
%       \mathit{mAlgebra}_{(a,b)} :: m~(a,b) \to (a,b) \\
%       \mathit{mAlgebra}_{(a,b)}~\mathit{ab} = (\mathit{mAlgebra}_a~(\mathit{fmap}_m~\mathit{fst}~\mathit{ab}), \mathit{mAlgebra}_b~(\mathit{fmap}_m~\mathit{snd}~\mathit{ab}))
%     \end{array}
%   \end{displaymath}
%   where $\mathit{fst}$ and $\mathit{snd}$ are the first and second
%   projections from the tuple type, respectively.
% \end{enumerate}

Finally in this short introduction to Eilenberg-Moore algebras, we
define homomorphisms between $m$-Eilenberg-Moore-algebras. These are
exactly the same as homomorphisms between $f$-algebras that we defined
in \autoref{sec:f-algebras}.

\begin{definition}
  An \emph{$m$-Eilenberg-Moore-algebra homomorphism}
  \begin{displaymath}
    h :: (a, \mathit{mAlgebra}_a) \to (b, \mathit{mAlgebra}_b)
  \end{displaymath}
  consists of a function $h :: a \to b$ such that:
  \begin{equation}
    \label{eq:em-alg-homomorphism}
    h \circ \mathit{mAlgebra}_a = \mathit{mAlgebra}_b \circ \mathit{fmap}_m~h
  \end{equation}
\end{definition}

\subsection{Definition of $f$-and-$m$-algebras}

As we indicated above, an $f$-and-$m$-algebra is consists of an
$f$-algebra and an $m$-Eilenberg-Moore-algebra with the same
carrier. Intuitively, the $f$-algebra part deals with the pure parts
of the structure, and the $m$-Eilenberg-Moore-algebra part deals with
the effectful parts. We require the extra structure of an
Eilenberg-Moore algebra in order to account for the potential merging
of the effects that are present between the layers of the inductive
datatype.

\begin{definition}
  An \emph{$f$-and-$m$-algebra} consists of a triple
  $(a,\mathit{fAlgebra},\mathit{mAlgebra})$ of an object $a$ and two
  functions:
  \begin{displaymath}
    \programmath
    \begin{array}{rcl}
      \mathit{fAlgebra} & :: & f~a \to a \\
      \mathit{mAlgebra} & :: & m~a \to a
    \end{array}
  \end{displaymath}
  where $\mathit{mAlgebra}$ is an $m$-Eilenberg-Moore algebra.
\end{definition}

Homomorphisms of $f$-and-$m$-algebras are single functions that are
simultaneously $f$-algebra homomorphisms and
$m$-Eilenberg-Moore-algebra homomorphisms:

\begin{definition}
  An \emph{$f$-and-$m$-algebra homomorphism}
  \begin{displaymath}
    h :: (a, \mathit{fAlgebra}_a, \mathit{mAlgebra}_a) \to (b, \mathit{fAlgebra}_b, \mathit{mAlgebra}_b)
  \end{displaymath}
  between two $f$-and-$m$ algebras is a function $h :: a \to b$ such
  that:
  \begin{displaymath}
    \begin{array}{rcl}
      h \circ \mathit{fAlgebra}_a & = & \mathit{fAlgebra}_b \circ \mathit{fmap}_f~h \\
      h \circ \mathit{mAlgebra}_a & = & \mathit{mAlgebra}_b \circ \mathit{fmap}_m~h
    \end{array}
  \end{displaymath}
\end{definition}

Given the above definitions, the definition of initial
$f$-and-$m$-algebras is straightforward, and follows the same
structure as for initial $f$-algebras. Abstractly, an initial
$f$-and-$m$-algebra is an initial object in the category of
$f$-and-$m$-algebras and $f$-and-$m$-algebra homomorphisms. We use the
notation $\mu(f|m)$ for carriers initial $f$-and-$m$-algebras to
indicate the interleaving of pure data (represented by $f$) and
effects (represented by $m$).

\begin{definition}
  An \emph{initial $f$-and-$m$-algebra} is an $f$-and-$m$-algebra
  $(\mu(f|m), \mathit{construct}_f, \mathit{construct}_m)$ such that
  for any $f$-and-$m$-algebra $(a, \mathit{fAlgebra}_a,
  \mathit{mAlgebra}_a)$, there exists a unique $f$-and-$m$-algebra
  homomorphism $\eFold{\mathit{fAlgebra}_a}{\mathit{mAlgebra}_a} ::
  \mu(f|m) \to a$.
\end{definition}

As for initial $f$-algebras, the requirement that an initial
$f$-and-$m$-algebra always has an $f$-and-$m$-algebra homomorphism to
any other $f$-and-$m$-algebra allows us to define functions on the
carriers of initial $f$-and-$m$-algebras. The uniqueness requirement
yields the following proof principle for functions defined on initial
$f$-and-$m$-algebras. It follows the same basic form as
\proofprinref{pp:initial-alg} for initial $f$-algebras, but also
includes an obligation to prove that the right-hand side of the
equation to be shown is an $m$-Eilenberg-Moore-algebra
homomorphism.

\begin{proofprinciple}[Initial $f$-and-$m$-Algebras]
  \label{pp:initial-f-m-alg}
  Suppose that $(\mu(f|m), \mathit{construct}_f, \mathit{construct}_m)$ is an
  initial $f$-and-$m$-algebra. 

  Let $(a, \mathit{fAlgebra}, \mathit{mAlgebra})$ be some
  $f$-and-$m$-algebra, and let
  $\eFold{\mathit{fAlgebra}}{\mathit{mAlgebra}}$ denote the induced
  function of type $\mu(f,m) \to a$. For any function $g :: \mu(f,m)
  \to a$, we can prove the equation:
  \begin{displaymath}
    \eFold{\mathit{fAlgebra}}{\mathit{mAlgebra}} = g
  \end{displaymath}
  by demonstrating that
  \begin{equation}\label{eq:fm-falg}
    g \circ \mathit{construct}_f = \mathit{fAlgebra} \circ \mathit{fmap}_f
  \end{equation}
  and
  \begin{equation}\label{eq:fm-malg}
    g \circ \mathit{construct}_m = \mathit{mAlgebra} \circ \mathit{fmap}_m
  \end{equation}
\end{proofprinciple}

The key feature of \proofprinref{pp:initial-f-m-alg} is that it
cleanly splits the pure and effectful proof obligations. Therefore we
may use this principle to cleanly reason about programs that operate
on interleaved pure and effectful data at a high level of abstraction,
unlike the direct reasoning we carried out in
\autoref{sec:direct-eappend}. We shall see this separation in action
for our list append running example in the next section.

\begin{example}
  The $\mathit{List}~m~a$ datatype that we defined in the introduction
  can be presented as the carrier of an initial
  $(\mathit{ListF}~a)$-and-$m$-algebra. The $\mathit{construct_f}$
  function is defined as follows:
  \begin{displaymath}
    \begin{array}{l}
      \mathit{construct_f} :: \mathit{ListF}~a~(\mathit{List}~m~a) \to \mathit{List}~m~a \\
      \begin{array}{@{}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
        \mathit{construct_f}~\mathsf{Nil}&=&\mathsf{List}~(\mathit{return_m}~\mathsf{Nil_m}) \\
        \mathit{construct_f}~(\mathsf{Cons}~a~\mathit{xs})&=&\mathsf{List}~(\mathit{return_m}~(\mathsf{Cons_m}~a~\mathit{xs})) \\
      \end{array}
    \end{array}
  \end{displaymath}
  The $\mathit{construct_m}$ component is slightly complicated by the
  presence of the $\mathsf{List}$ constructor. We use Haskell's
  $\kw{do}$ notation for convenience:
  \begin{displaymath}
    \begin{array}{l}
      \mathit{construct_m} :: m~(\mathit{List}~m~a) \to \mathit{List}~m~a \\
      \mathit{construct_m}~\mathit{ml} = \mathsf{List}~(\kw{do}~\{ \mathsf{List}~x \leftarrow \mathit{ml}; x \})
    \end{array}
  \end{displaymath}
  Finally, we define the induced homomorphism to any other
  $(\mathit{ListF}~a)$-and-$m$-algebra as a pair of mutually recursive
  functions, following the structure of the declaration of
  $\mathit{List}~m~a$:
  \begin{displaymath}
    \begin{array}{l}
      \eFold{-}{-} :: (f~a \to a) \to (m~a \to a) \to \mathit{List}~m~a \to a \\
      \eFold{\mathit{fAlgebra}}{\mathit{mAlgebra}} = \mathit{loop} \\
      \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
        \kw{where} & \mathit{loop}~(\mathsf{List}~x) &=& \mathit{mAlgebra}~(\mathit{fmap}_m~\mathit{loop'}~x) \\
        & \mathit{loop'}~\mathsf{Nil_m}& = & \mathit{fAlgebra}~\mathsf{Nil} \\
        & \mathit{loop'}~(\mathsf{Cons_m}~a~\mathit{xs}) &=& \mathit{fAlgebra}~(\mathsf{Cons}~a~(\mathit{loop}~\mathit{xs}))
      \end{array}
    \end{array}
  \end{displaymath}
\end{example}
We will give a general construction of initial $f$-and-$m$-algebras in
\autoref{sec:f-and-m-alg-impl} that builds on the generic definition
of initial $f$-algebras from \autoref{sec:f-algebras}. The key result
is that the existence of initial $f$-and-$m$-algebras can be reduced
to the existence of initial $(f \circ m)$-algebras: this is
\thmref{thm:make-initial-f-and-m-alg} below.

\section{List append III: lists with interleaved effects, via $f$-and-$m$-algebras}
\label{sec:f-and-m-append}

We now revisit the problem of defining and proving associativity for
append on lists interleaved with effects that we examined in
\autoref{sec:direct-eappend}. We use the abstraction of (initial)
$f$-and-$m$-algebras, firstly to simplify the implementation of
$\mathit{eAppend}$ from \autoref{sec:direct-eappend}, and secondly to
simplify the proof of associativity. We shall see that both the
definition and proof mirror the definition and proof from the
pure case we presented in \autoref{sec:pure-append}.

By separating the pure and effectful parts of the proof,
\proofprinref{pp:initial-f-m-alg} allows us to reuse proofs from the
pure case. Therefore, it makes sense to ask when the additional
condition (\autoref{eq:fm-falg}) that it imposes fails. We examine an
instance of this in \autoref{sec:reverse}, where a standard property
of list reverse fails to carry over to the case of lists with
interleaved effects.

\subsection{Append for lists with interleaved effects}

We define our function $\mathit{eAppend}$ against the abstract
interface of initial $(\mathit{ListF}~a)$-and-$m$-algebras that we
defined in the previous section. Hence we assume that an initial
$(\mathit{ListF}~a)$-and-$m$-algebra $(\mu(\mathit{ListF}~a|m),
\mathit{construct}_{\mathit{ListF}~a}, \mathit{construct}_m)$ exists,
and we denote the unique $(\mathit{ListF}~a)$-and-$m$-algebra
homomorphism using the notation $\eFold{-}{-}$. We can define the
function $\mathit{eAppend}$ in terms of initial $f$-and-$m$-algebras
as:
\begin{displaymath}
  \begin{array}{l}
    \mathit{eAppend} :: \mu(\mathit{ListF}~a|m) \to \mu(\mathit{ListF}~a|m) \to \mu(\mathit{ListF}~a|m) \\
    \mathit{eAppend}~\mathit{xs}~\mathit{ys} = \eFold{\mathit{fAlgebra}}{\mathit{construct}_m}~\mathit{xs} \\
    \begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
      \textbf{where} & \mathit{fAlgebra}~\mathsf{Nil} &=& \mathit{ys} \\
                     & \mathit{fAlgebra}~(\mathsf{Cons}~a~\mathit{xs}) &=& \mathit{construct}_{\mathit{ListF}~a}~(\mathsf{Cons}~a~\mathit{xs})      
    \end{array}
  \end{array}
\end{displaymath}
Note that, unlike the direct definition of $\mathit{eAppend}$ that we
made in \autoref{sec:direct-eappend}, this definition is almost
identical to the definition of the function $\mathit{append}$ from
\autoref{sec:pure-append}. The only differences are the additional
$m$-Eilenberg-Moore-algebra argument to $\eFold{-}{-}$ and the
different type of $\mathit{construct}_{\mathit{ListF}~a}$. The fact
that the pure part of definition (i.e.,~the function
$\mathit{fAlgebra}$) is almost identical to the $\mathit{fAlgebra}$ in
the definition of $\mathit{append}$ is a result of the separation of
pure and effectful concerns that the abstraction of
$f$-and-$m$-algebras affords.

Just as in the case of $\mathit{append}$, we can immediately read off
two properties of $\mathit{eAppend}$ from the fact that it constructed
as a $(\mathit{ListF}~a)$-algebra homomorphism. We have one property
for each of the constructors of the type constructor
$\mathit{ListF}~a$:
\begin{align}
  \label{eq:eAppend-nil}
  \mathit{eAppend}~(\mathit{construct}_{\mathit{ListF}~a}~\mathsf{Nil})~\mathit{ys} & = \mathit{ys} \\
  \label{eq:eAppend-cons}
  \mathit{eAppend}~(\mathit{construct}_{\mathit{ListF}~a}~(\mathsf{Cons}~a~\mathit{xs}))~\mathit{ys} & = \mathit{construct}_{\mathit{ListF}~a}~(\mathsf{Cons}~a~(\mathit{eAppend}~\mathit{xs}~\mathit{ys}))
\end{align}
Again by construction, we also know that $\mathit{eAppend}$ is an
$m$-Eilenberg-Moore-algebra homomorphism. Hence we have the following
property of $\mathit{eAppend}$ for free. For all $x ::
m~(\mu(\mathit{ListF}~a|m))$:
\begin{equation}\label{eq:eappend-em}
  \mathit{eAppend}~(\mathit{construct}_m~\mathit{x})~\mathit{ys} = \mathit{construct}_m~(\mathit{fmap}_m~(\lambda \mathit{xs}.~\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{x})
\end{equation}

With these three properties of $\mathit{eAppend}$ in hand we can prove
that it is associative. We use \proofprinref{pp:initial-f-m-alg},
which splits the proof into the pure and effectful parts. As we shall
see, the pure part of the proof, where the real work happens, is
identical to the proof steps we took in the proof of
\thmref{thm:append-assoc}. The effectful parts of the proof are
straightforward, following directly from the fact that
$\mathit{eAppend}$ is an $m$-Eilenberg-Moore-algebra homomorphism
(\autoref{eq:eappend-em}).

\begin{theorem}
  For all $\mathit{xs}, \mathit{ys}, \mathit{zs} :: \mu(\mathit{ListF}~a|m)$,
  \begin{displaymath}
    \mathit{eAppend}~\mathit{xs}~(\mathit{eAppend}~\mathit{ys}~\mathit{zs}) = \mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs}
  \end{displaymath}
\end{theorem}

\begin{proof*}
  The function $\mathit{eAppend}$ is defined in terms of the initial
  algebra property of $\mu(\mathit{ListF}~a|m)$, so we can apply
  \proofprinref{pp:initial-f-m-alg}. Thus we must prove
  \autoref{eq:fm-falg} and \autoref{eq:fm-malg}. Firstly, for all $x
  :: \mathit{ListF}~a~(\mu(\mathit{ListF}~a|m))$, we must show that
  \autoref{eq:fm-falg} holds, i.e. that:
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{eAppend}~(\mathit{eAppend}~(\mathit{construct}_{\mathit{ListF}~a}~x)~\mathit{ys})~\mathit{zs}\\
      =&\mathit{fAlgebra}~(\mathit{fmap}_{\mathit{ListF}~a}~(\lambda \mathit{xs}.~\mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs})~x)
    \end{array}
  \end{displaymath}
  where
  \begin{displaymath}
    \begin{array}{rcl}
      \mathit{fAlgebra}~\mathsf{Nil} &=& \mathit{eAppend}~\mathit{ys}~\mathit{zs} \\
      \mathit{fAlgebra}~(\mathsf{Cons}~a~\mathit{xs}) &=& \mathit{construct}_{\mathit{ListF}~a}~(\mathsf{Cons}~a~\mathit{xs})
    \end{array}
  \end{displaymath}
  This equation is, up to renaming, \emph{exactly the same} as the
  equation we had to show in proof of
  \thmref{thm:append-assoc}. Therefore, we use the same reasoning
  steps to show this equation, relying on the properties of
  $\mathit{eAppend}$ captured above in \autoref{eq:eAppend-nil} and
  \autoref{eq:eAppend-cons}.

  Secondly, we must show that the right-hand side of the equation to
  be proved is an $m$-Eilenberg-Moore-algebra homomorphism, i.e., the
  \autoref{eq:fm-malg} holds:
  \begin{displaymath}
    \begin{array}{cl}
      &\mathit{eAppend}~(\mathit{eAppend}~(\mathit{construct}_m~x)~\mathit{ys})~\mathit{zs} \\
      =&\mathit{construct}_m~(\mathit{fmap}_m~(\lambda \mathit{xs}.~\mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs})~x)
    \end{array}
  \end{displaymath}
  This follows straightforwardly from the fact that $\mathit{eAppend}$
  is itself an $m$-Eilenberg-Moore-algebra homomorphism, as we noted
  above in \autoref{eq:eappend-em}, and that such homomorphisms are closed under composition:
  \begin{displaymath}
    \begin{array}{cl}
      & \mathit{eAppend}~(\mathit{eAppend}~(\mathit{construct}_m~x)~\mathit{ys})~\mathit{zs} \\
      =&\eqAnnotationS{\autoref{eq:eappend-em}} \\
      & \mathit{eAppend}~(\mathit{construct}_m~(\mathit{fmap}_m~(\lambda \mathit{xs}.~\mathit{eAppend}~\mathit{xs}~\mathit{ys})~x))~\mathit{zs} \\
      =&\eqAnnotationS{\autoref{eq:eappend-em}} \\
      & \mathit{construct_m}~(\mathit{fmap}_m~(\lambda \mathit{xs}.~\mathit{eAppend}~\mathit{xs}~\mathit{zs})~(\mathit{fmap}_m~(\lambda \mathit{xs}.~\mathit{eAppend}~\mathit{xs}~\mathit{ys})~x)) \\
      =&\eqAnnotationS{$\mathit{fmap}_m$ preserves function composition (\autoref{eq:fmap-comp})} \\
      & \mathit{construct_m}~(\mathit{fmap}_m~(\lambda \mathit{xs}.~\mathit{eAppend}~(\mathit{eAppend}~\mathit{xs}~\mathit{ys})~\mathit{zs})~x) \mathproofbox
    \end{array}
  \end{displaymath}
\end{proof*}
As promised, the proof that $\mathit{eAppend}$ is associative, using
\proofprinref{pp:initial-f-m-alg}, is much simpler than the direct
$f$-algebra proof we attempted in \autoref{sec:direct-eappend}. In
addition, the separation of pure and effectful parts has meant that we
were able to reuse the proof of the pure case from
\autoref{sec:pure-append}, and so need only to establish the side
condition for effects.

\subsection{Reverse for lists with interleaved effects?}
\label{sec:reverse}

Given the above example of a proof of a property of a function on pure
lists carrying over almost unchanged to lists interleaved with
effects, one might wonder if there are circumstances where this
approach fails. Clearly, it cannot be the case that all properties
true for pure lists carry over to effectful lists. One example of a
property that fails to carry over is the following property of the
reverse function:
\begin{equation}\label{eq:reverse-append}
  \mathit{reverse}~(\mathit{append}~\mathit{xs}~\mathit{ys}) = \mathit{append}~(\mathit{reverse}~\mathit{ys})~(\mathit{reverse}~\mathit{xs})
\end{equation}
Intuitively, this property cannot possibly hold for a reverse function
on lists interleaved with effects, since in order to reverse a list,
all of the effects inside it must be executed in order to reach the
last element and place it at the head of the new list. Thus the left
hand side of the equation above will execute all the effects of
$\mathit{xs}$ and then $\mathit{ys}$ in order, whereas the right hand
side will execute all the effects of $\mathit{ys}$ first, and then
$\mathit{xs}$. If we try to prove this property using
\proofprinref{pp:initial-f-m-alg}, we see that we are unable to prove
\autoref{eq:fm-malg}, namely that the right-hand side must be an
Eilenberg-Moore-algebra homomorphism.

We can define a reverse function on effectful lists as follows. This
is very similar to the standard definition of (non-tail recursive)
reverse on pure lists, and makes use of the $\mathit{eAppend}$
function we defined above.
\begin{displaymath}
  \begin{array}{l}
    \mathit{eReverse} :: \mu(\mathit{ListF}~a|m) \to \mu(\mathit{ListF}~a|m) \\
    \mathit{eReverse} = \eFold{\mathit{fAlgebra}}{\mathit{construct}_m} \\
    \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
      \kw{where} & \mathit{fAlgebra}~\mathsf{Nil} &=& \mathit{construct}_{\mathit{ListF}~a}~\mathsf{Nil} \\
      & \mathit{fAlgebra}~(\mathsf{Cons}~a~\mathit{xs}) &=& \mathit{eAppend}~\mathit{xs}~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{construct}~\mathsf{Nil})))
    \end{array}
  \end{array}
\end{displaymath}
Verifying the effectful analogue of \autoref{eq:reverse-append} requires a little extra step
before we can apply \proofprinref{pp:initial-f-m-alg}, because the
left-hand side of the equation is constructed from a composite of two
functions of the form $\eFold{-}{-}$. However, it is
straightforward to prove that this composite is equal to
$\eFold{\mathit{alg}}{\mathit{construct}_m}$, where
\begin{displaymath}
  \begin{array}{l}
    \mathit{alg} :: \mathit{ListF}~a~(\mu(\mathit{ListF}~a|m)) \to \mu(\mathit{ListF}~a|m) \\
    \begin{array}{@{}l@{\hspace{0.5em}}lcl}
      \mathit{alg}&\mathsf{Nil} &=& \mathit{eReverse}~\mathit{ys} \\
      \mathit{alg}&(\mathsf{Cons}~a~\mathit{xs}) & =& \mathit{eAppend}~\mathit{xs}~(\mathit{construct}~(\mathsf{Cons}~a~(\mathit{construct}~\mathsf{Nil})))
    \end{array}
  \end{array}
\end{displaymath}
This same extra step is required in the case for pure datatypes as
well, so this is not where the problem with interleaved effects
lies. If we attempt to apply \proofprinref{pp:initial-f-m-alg} to the
equation:
\begin{displaymath}
  \eFold{\mathit{alg}}{\mathit{construct}_m}~\mathit{xs} = \mathit{eAppend}~(\mathit{eReverse}~\mathit{ys})~(\mathit{eReverse}~\mathit{xs})
\end{displaymath}
Then the pure part of the proof goes through straightforwardly. We are
left with proving that the right hand side of this equation is an
Eilenberg-Moore-algebra homomorphism in its second
argument. Certainly, $\mathit{eReverse}$ is an Eilenberg-Moore-algebra
homomorphism by its construction via the initial $f$-and-$m$-algebra
property. However, $\mathit{eAppend}$ is not an Eilenberg-Moore
algebra homomorphism in its \emph{second} argument, as the following
counterexample shows. If we let the monad $m$ be the $\mathit{ErrorM}$
monad we defined in \autoref{sec:eilenberg-moore-algebras}, then if
$\mathit{eAppend}$ were an Eilenberg-Moore-algebra homomorphism in its
second argument the following equation would hold:
\begin{equation}\label{eq:purported-em}
  \begin{array}{cl}
    &\mathit{eAppend}~(\mathit{construct}_f~(\mathsf{Cons}~a~(\mathit{construct}_f~\mathsf{Nil})))~(\mathit{construct}_{\mathit{ErrorM}}~(\mathsf{Error}~\texttt{"msg"})) \\
    =&\mathit{construct}_{\mathit{ErrorM}}~\\
    & \hspace{1cm}(\mathit{fmap}_{\mathit{ErrorM}}~(\lambda ys.~\mathit{eAppend}~(\mathit{construct}_f~(\mathsf{Cons}~a~(\mathit{construct}_f~\mathsf{Nil}))))~\\
    & \hspace{1.5cm}(\mathsf{Error}~\texttt{"msg"}))
  \end{array}
\end{equation}
However, starting from the left-hand side, we calculate as follows:
\begin{displaymath}
  \begin{array}{cl}
    & \mathit{eAppend}~(\mathit{construct}_f~(\mathsf{Cons}~a~(\mathit{construct}_f~\mathsf{Nil})))~(\mathit{construct}_{\mathit{ErrorM}}~(\mathsf{Error}~\texttt{"msg"})) \\
    =&\eqAnnotation{\autoref{eq:eAppend-cons}} \\
    & \mathit{construct}_f~(\mathit{Cons}~a~(\mathit{eAppend}~(\mathit{construct}_f~\mathsf{Nil})~(\mathit{construct}_{\mathit{ErrorM}}~(\mathsf{Error}~\texttt{"msg"})))) \\
    =&\eqAnnotation{\autoref{eq:eAppend-nil}} \\
    & \mathit{construct}_f~(\mathit{Cons}~a~(\mathit{construct}_{\mathit{ErrorM}}~(\mathsf{Error}~\texttt{"msg"})))
  \end{array}
\end{displaymath}
while the right hand side of \autoref{eq:purported-em} reduces by the
definition of $\mathit{fmap}_{\mathit{ErrorM}}$ to simply:
\begin{displaymath}
  \mathit{construct}_{\mathit{ErrorM}}~(\mathsf{Error}~\texttt{"msg"})
\end{displaymath}
Thus the proof fails. This is the formal rendering of the intuition
for the failure given at the start of this subsection.

% As a consequence, the involution property:
% \begin{displaymath}
%   \mathit{eReverse}~(\mathit{eReverse}~\mathit{xs}) = \mathit{xs}
% \end{displaymath}
% does not hold in the presence of arbitrary interleaved
% effects. Intuitively, it is again clear why: the expression on the
% left pushes all the effects to the start of the list as
% $\mathit{eReverse}$ traverses the list, while the right-hand side
% leaves the effects interspersed between the elements.

\section{Generic implementation of initial $f$-and-$m$-algebras}
\label{sec:impl-f-and-m}

We have seen that existing datatypes such as $\mathit{List}~m~a$ can
be given the structure of initial $f$-and-$m$-algebras. In this
section, we show that, in Haskell, we can implement an initial
$f$-and-$m$-algebra for and functor $f$ and monad $m$. We build on the
generic implementation of initial $f$-algebras we presented in
\autoref{sec:example-initial-f}. The key construction is to show that
if we have an initial $(f \circ m)$-algebra, then we can construct an
initial $f$-and-$m$-algebra.


\subsection{From initial $(f \circ m)$-algebras to initial $f$-and-$m$-algebras}

Initial $f$-and-$m$-algebras can be constructed from initial $(f \circ
m)$-algebras. If the type $\mu(f \circ m)$ is the carrier of an
initial $(f \circ m)$-algebra, then the initial $f$-and-$m$-algebra
that we construct has carrier $m~(\mu (f \circ m))$. One way of
looking at the proof of the following theorem is as containing all the
additional parts of the definition and proof steps we carried out in
the direct initial $f$-algebra proof of associativity in
\autoref{sec:direct-eappend} that were missing in the initial
$f$-and-$m$-algebra approach in the previous section. Thus we have
abstracted out parts that are common to all definitions and proofs
that have to do with interleaved data and effects.

\begin{theorem}\label{thm:make-initial-f-and-m-alg}
  Let $(f, \mathit{fmap}_f)$ be a functor, and $(m, \mathit{fmap}_m,
  \mathit{return}_m, \mathit{join}_m)$ be a monad.  If we have an
  initial $(f \circ m)$-algebra $(\mu(f \circ m),
  \mathit{construct})$, then $m~(\mu(f \circ m))$ is the carrier of an
  initial $f$-and-$m$-algebra.
\end{theorem}

\begin{proof*}
  The $f$-algebra and $m$-Eilenberg-Moore-algebra structure are
  constructed from the $(f \circ m)$-algebra structure map
  $\mathit{construct}$ and the structure of the monad $m$.  For the
  $f$-algebra component, we use the composite:
  \begin{displaymath}
    \mathit{construct}_f = \mathit{return}_m \circ \mathit{construct} :: f~(m~(\mu(f \circ m))) \to m~(\mu(f \circ m))
  \end{displaymath}
  The $m$-Eilenberg-Moore-algebra component is straightforward, using
  the free Eilenberg-Moore-algebra construction from
  \autoref{sec:eilenberg-moore-algebras}:
  \begin{displaymath}
    \mathit{construct}_m = \mathit{join}_m :: m~(m~(\mu(f \circ m))) \to m~(\mu(f \circ m))
  \end{displaymath}
  Since we have used the free Eilenberg-Moore-algebra construction, we
  are automatically guaranteed that we have an
  $m$-Eilenberg-Moore-algebra.

  Now let us assume we are given an $f$-and-$m$-algebra $(a,
  \mathit{fAlgebra}_a, \mathit{mAlgebra}_a)$. We construct, and prove
  unique, an $f$-and-$m$-algebra homomorphism $h$ from the algebra
  $(m~(\mu(f \circ m)), \mathit{construct}_f, \mathit{construct}_m)$
  to the algebra with carrier $a$ using the initiality of $\mu(f \circ
  m)$:
  \begin{displaymath}
    h = \mathit{mAlgebra}_a \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a} :: m~(\mu(f \circ m)) \to a
  \end{displaymath}
  Close inspection of $h$ reveals that it has the same structure as
  the definition of $\mathit{eAppend}$ in terms of initial
  $f$-algebras we gave in \autoref{sec:direct-eappend}. Therefore, as
  we noted in the introduction to this subsection, the construction we
  are buliding here abstracts out the common parts of proofs and
  definitions on effectful datatypes.

  To complete our proof, we now need to demonstrate that $h$ is an
  $f$-and-$m$-algebra homomorphism, and that it is the unique such. We
  split this task into three steps:
  \begin{enumerate}
  \item The function $h$ is an $f$-algebra homomorphism. We reason as
    follows:
    \begin{displaymath}
      \begin{array}{cl}
        & h \circ \mathit{construct}_f \\
        =&\eqAnnotation{definitions of $h$ and $\mathit{construct_f}$} \\
         &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a} \circ \mathit{return}_m \circ \mathit{construct} \\
        =&\eqAnnotation{naturality of $\mathit{return}_m$ (\autoref{eq:monad-return-natural})} \\
         &\mathit{mAlgebra}_a \circ \mathit{return}_m \circ \fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a} \circ \mathit{construct} \\
        =&\eqAnnotation{$\mathit{mAlgebra}_a$ is an $m$-Eilenberg-Moore-algebra (\autoref{eq:em-alg-return})} \\
         &\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a} \circ \mathit{construct} \\
        =&\eqAnnotation{$\fold{-}$ is an $(f \circ m)$-algebra homomorphism (\autoref{eq:falgebra-homomorphism})} \\
         &\mathit{fAlgebra}_a \circ \\
         & \hspace{1cm}\mathit{fmap}_f~\mathit{mAlgebra}_a \circ \mathit{fmap}_f~(\mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a}) \\
        =&\eqAnnotation{$\mathit{fmap}_f$ preserves function composition (\autoref{eq:fmap-comp})} \\
         &\mathit{fAlgebra}_a \circ \mathit{fmap}_f~(\mathit{mAlgebra}_a \circ \mathit{fmap_m}~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a}) \\
        =&\eqAnnotation{definition of $h$} \\
         & \mathit{fAlgebra}_a \circ \mathit{fmap}_f~h
      \end{array}
    \end{displaymath}
  \item The function $h$ is an $m$-Eilenberg-Moore-algebra
    homomorphism, as shown by the following steps:
    \begin{displaymath}
      \begin{array}{cl}
        & h \circ \mathit{construct_m} \\
        =&\eqAnnotation{definitions of $h$ and $\mathit{construct}_m$} \\
         &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a} \circ \mathit{join}_m \\
        =&\eqAnnotation{naturality of $\mathit{join}_m$ (\autoref{eq:monad-join-natural})} \\
         &\mathit{mAlgebra}_a \circ \mathit{join}_m \circ \mathit{fmap}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a}) \\
        =&\eqAnnotation{$\mathit{mAlgebra}_a$ is an Eilenberg-Moore algebra (\autoref{eq:em-alg-join})} \\
         &\mathit{mAlgebra}_a \circ \\
         &\hspace{1cm}\mathit{fmap}_m~\mathit{mAlgebra}_a \circ \mathit{fmap}_m~(\mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a}) \\
        =&\eqAnnotation{$\mathit{fmap}_m$ preserves function composition (\autoref{eq:fmap-comp})} \\
         &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~(\mathit{mAlgebra}_a \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a}) \\
        =&\eqAnnotation{definition of $h$} \\
         &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~h
      \end{array}
    \end{displaymath}
  \item The function $h$ is the unique such $f$-and-$m$-algebra. Let
    us assume that there exists another $f$-and-$m$-algebra
    homomorphism $h' :: m~(\mu(f \circ m)) \to a$. We aim to show that
    $h = h'$. We first observe that the following function defined by composition:
    \begin{displaymath}
      h' \circ \mathit{return}_m :: \mu(f \circ m) \to a
    \end{displaymath}
    is an $(f \circ m)$-algebra homomorphism
    from $(\mu(f \circ m), \mathit{construct})$ to $(a, \mathit{fAlgebra}_a
    \circ \mathit{fmap}_f~\mathit{mAlgebra}_a)$, as verified by the
    following steps:
    \begin{displaymath}
      \begin{array}{cl}
        & h' \circ \mathit{return}_m \circ \mathit{construct} \\
        =&\eqAnnotationS{definition of $\mathit{construct}_f$} \\
        & h' \circ \mathit{construct}_f \\
        =&\eqAnnotationS{$h'$ is an $f$-and-$m$-algebra homomorphism} \\
        & \mathit{fAlgebra}_a \circ \mathit{fmap}_f~h' \\
        =&\eqAnnotationS{monad law: $\mathit{join}_m \circ \mathit{fmap}_m~\mathit{return}_m = \mathit{id}$ (\autoref{eq:monad-join-fmap-return})} \\
        & \mathit{fAlgebra}_a \circ \mathit{fmap}_f~(h' \circ \mathit{join}_m \circ \mathit{fmap}_m~\mathit{return}_m) \\
        =&\eqAnnotationS{$h'$ is an $m$-Eilenberg-Moore-algebra homomorphism (\autoref{eq:em-alg-homomorphism})} \\
        & \mathit{fAlgebra}_a \circ \mathit{fmap}_f~(\mathit{mAlgebra}_a \circ \mathit{fmap}_m~h' \circ \mathit{fmap}_m~\mathit{return}_m) \\
        =&\eqAnnotationS{$\mathit{fmap}_f$ preserves function composition (\autoref{eq:fmap-comp})} \\
        & \mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a \circ \mathit{fmap}_f~(\mathit{fmap}_m~(h' \circ \mathit{return}_m))
      \end{array}
    \end{displaymath}
    Thus, by the uniqueness of $(f \circ m)$-algebra homomorphisms out
    of $\mu(f \circ m)$, we have proved that 
    \begin{equation}\label{eq:h'-prop}
      h' \circ \mathit{return}_m = \fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a}
    \end{equation}
    We now use this equation to prove that $h=h'$ by the following
    steps:
    \begin{displaymath}
      \begin{array}{cl}
        & h \\
        =&\eqAnnotationS{definition of $h$} \\
        &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra}_a \circ \mathit{fmap}_f~\mathit{mAlgebra}_a} \\
        =&\eqAnnotationS{\autoref{eq:h'-prop}} \\
        &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~(h' \circ \mathit{return}_m) \\
        =&\eqAnnotationS{$\mathit{fmap}_m$ preserves function composition (\autoref{eq:fmap-comp})} \\
        &\mathit{mAlgebra}_a \circ \mathit{fmap}_m~{h'} \circ \mathit{fmap}_m~\mathit{return}_m \\
        =&\eqAnnotationS{$h'$ is an $m$-Eilenberg-Moore-algebra homomorphism (\autoref{eq:em-alg-homomorphism})} \\
        &h' \circ \mathit{join}_m \circ \mathit{fmap}_m~\mathit{return}_m \\
        =&\eqAnnotationS{monad law: $\mathit{join}_m \circ \mathit{fmap}_m~\mathit{return}_m = \mathit{id}$} \\
        &h'
      \end{array}
    \end{displaymath}
    Thus $h$ is the unique $f$-and-$m$-algebra homomorphism from
    $m~(\mu (f \circ m))$ to $a$. \mathproofbox
  \end{enumerate}
\end{proof*}

In the current authors' previous work \cite{atkey12fibrational}, this
same result was obtained in a less elementary way by constructing a
functor $\Phi$ from the category of $(f \circ m)$-algebras to the
category of $f$-and-$m$-algebras. The functor $\Phi$ was shown to be a
left adjoint, and since left adjoints preserve initial objects, $\Phi$
maps any initial $(f \circ m)$-algebra to an initial
$f$-and-$m$-algebra.

% FIXME: mention Filinski and Stvring's construction?

\subsection{Implementation of initial $f$-and-$m$-algebras in Haskell}
\label{sec:f-and-m-alg-impl}

\newcommand{\fcompose}{\mathop{\mathord:\circ\mathord:}}

In light of \thmref{thm:make-initial-f-and-m-alg}, we can take the
Haskell implementation of initial $f$-algebras from
\autoref{sec:f-algebras} and apply the construction in the
theorem to construct an initial $f$-and-$m$-algebra. We do have to
make a small alteration to satisfy Haskell's type checker, however.

The seed of our construction is the existence of an initial $(f \circ
m)$-algebra. Therefore, we need to first construct the composite
functor $f \circ m$. Since Haskell does not have type-level
$\lambda$-abstraction or application, there is no lightweight way of
constructing the composite of two functors' type operator
components. Thus to express the composition of two type operators as
a new type operator, we must introduce a $\kw{newtype}$, as
follows\footnote{This definition requires the GHC extension
  \texttt{-XTypeOperators} to be turned on, allowing infix type
  constructors.}:
\begin{displaymath}
  \kw{newtype}~(f \fcompose g)~a = \mathsf{C}~\{\mathit{unC} :: f~(g~a) \}
\end{displaymath}
We define $\mathit{fmap}_{f\fcompose g}$ straightforwardly in terms of
$\mathit{fmap}_f$ and $\mathit{fmap}_g$:
\begin{displaymath}
  \mathit{fmap}_{f\fcompose g}~h~(\mathsf{C}~x) = \mathsf{C}~(\mathit{fmap}_f~(\mathit{fmap}_g~h)~x)
\end{displaymath}

\thmref{thm:make-initial-f-and-m-alg} states that if $\mu(f \circ m)$
is the carrier of an initial $(f \circ m)$-algebra, then $m~(\mu(f
\circ m))$ is the carrier of an initial
$f$-and-$m$-algebra. Therefore, we define:
\begin{displaymath}
  \kw{type}~\mathit{MuFM}~f~m = m~(\mathit{Mu}~(f \fcompose m))
\end{displaymath}
with the $f$-algebra and $m$-Eilenberg-Moore-algebra structure maps
defined following the construction in
\thmref{thm:make-initial-f-and-m-alg}, augmented with a use of the
value constructor $\mathsf{C}$ to satisfy the type checker:
\begin{displaymath}
  \begin{array}{l}
    \mathit{construct}_f :: f~(\mathit{MuFM}~f~m) \to \mathit{MuFM}~f~m \\
    \mathit{construct}_f = \mathit{return}_m \circ \mathit{construct} \circ \mathsf{C} \\
    \\
    \mathit{construct}_m :: m~(\mathit{MuFM}~f~m) \to \mathit{MuFM}~f~m \\
    \mathit{construct}_m = \mathit{join}_m
  \end{array}
\end{displaymath}

Finally, we construct the unique $f$-and-$m$-homomorphism out of
$\mathit{MuFM}~f~m$ following the proof of
\thmref{thm:make-initial-f-and-m-alg} by building upon our
implementation of the unique homomorphisms out of the initial $(f
\fcompose m)$-algebra, albeit augmented with a coercion $\mathit{unC}
:: (f \fcompose m)~a \to f~(m~a)$ to satisfy the type checker:
\begin{displaymath}
  \begin{array}{l}
    \eFold{-}{-} :: (f~a \to a) \to (m~a \to a) \to \mathit{MuFM}~f~m \to a \\
    \eFold{\mathit{fAlgebra}}{\mathit{mAlgebra}} = \mathit{mAlgebra} \circ \mathit{fmap}_m~\fold{\mathit{fAlgebra} \circ \mathit{fmap}_f~\mathit{mAlgebra} \circ \mathit{unC}}
  \end{array}
\end{displaymath}
We can also implement $\eFold{-}{-}$ directly in terms of Haskell's
general recursion, just as we did for the implementation of
$\fold{-}$. This definition arises simply by inlining the
implementation of $\fold{-}$ into the definition of $\eFold{-}{-}$
above, and performing some simple rewriting. The direct implementation
of $\eFold{-}{-}$ is as follows:
\begin{displaymath}
  \begin{array}{l}
    \eFold{-}{-} :: (f~a \to a) \to (m~a \to a) \to \mathit{MuFM}~f~m \to a \\
    \eFold{\mathit{fAlgebra}}{\mathit{mAlgebra}} = \mathit{mAlgebra} \circ \mathit{fmap}_m~\mathit{loop} \\
    \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
      \kw{where} & \mathit{loop} &=& \mathit{fAlgebra} \circ \mathit{fmap}_f~\mathit{mAlgebra} \circ \mathit{fmap}_f~(\mathit{fmap}_m~\mathit{loop}) \circ \mathit{unC} \circ \mathit{unIn}
    \end{array}
  \end{array}
\end{displaymath}

Whichever implementation of $\eFold{-}{-}$ we choose, we note that
there is an implicit precondition that the second argument (of type
$m~a \to a$) must be an Eilenberg-Moore algebra. Unfortunately, we are
unable to express this requirement in Haskell's type system. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Application: Coproducts of free monads with arbitrary monads}
\label{sec:coproducts-with-free-monads}

To demonstrate the effectiveness of initial $f$-and-$m$-algebras for
programming with and reasoning about datatypes with interleaved
effects, we reconstruct a result originally due to Hyland, Plotkin and
Power \cite{hyland06combining} on the construction of coproducts of
free monads with arbitrary monads. This example highlights the
advantages that $f$-and-$m$-algebra's separation of pure data and
effects provides, and also has theoretical and practical interest. We
now give a brief explanation of the relevant concepts.

\emph{Monad coproducts} provide a canonical way of describing the
combination of two monads to form another monad. We formally define
the coproduct of two monads below, in
\autoref{sec:coproducts-of-monads}. For now, we can think of the
coproduct of two monads as the ``least commitment'' combination. The
coproduct of two monads is able to describe any effects that its
constituents describes, but imposes no interaction between
them. Unfortunately, the coproduct of two arbitrary monads is not
always guaranteed to exist. Monad coproducts are guaranteed to exist
in certain special cases. For example, ideal monads
\cite{ghani04coproducts}, or when working in the category of Sets
\cite{adamek12coproducts}, or if the monads are constructed from
algebraic theories \cite{hyland06combining}. One particular special
case is when one of the constituent monads is \emph{free}.

A \emph{Free monad} for a functor $(f, \mathit{fmap}_f)$ is the
``least commitment'' way of extending the functor $f$ to become a
monad. A useful application of free monads is as a way of describing
effectful computations over a set of commands, where the commands are described by the
functor $f$, and no commitment is made as to their interpretations. Swierstra and Altenkirch \cite{swierstra07beauty} have
developed this idea to provide a straightforward way of reasoning
about programs that perform input/output. We briefly describe this
view of free monads after we give the formal definition in
\autoref{sec:free-monads}.

Coproducts of free monads with arbitrary monads arise when considering
certain kinds of datatypes interleaved with effects, such as the
Iteratee type $\mathit{Reader}~m~a~b$ in
\autoref{sec:motivate-interleaving}. This type describes computations
that interleave the possibility of reading with performing effects in
some arbitrary monad (often the $\mathit{IO}$ monad). The power of the
$\mathit{Reader}~m~a~b$ type, as demonstrated by Kiselyov
\cite{kiselyov12iteratees}, is that we are provided with considerable
flexibility in how to interpret ``reading'', allowing for instances of
the type $\mathit{Reader}~m~a~b$ to be chained together in interesting
ways. The monad coproduct interface provides us with a simple,
general, and canonical way of precisely describing exactly how
$\mathit{Reader}~m~a~b$ is the combination of read effects with
effects in $m$.

In the next subsection, we present the formal definition of the notion of a free
monad, and briefly describe the reading of free monads as abstract
sequences of commands that can be interpreted in multiple ways. In
\autoref{sec:construct-free-monads}, we show that concrete free monads
can be defined using specific initial $f$-algebras. We will be able to reuse
most of this construction when constructing the coproduct in
\autoref{sec:construct-coproducts}. We present the formal definition of
monad coproduct in \autoref{sec:coproducts-of-monads}, and elaborate
on the reading of free monads as sequences of commands, now
interleaved with effects from some arbitrary monad. Finally, in
\autoref{sec:construct-coproducts}, we present a concrete construction
of the coproduct of a free monad with an arbitrary monad. By making
use of $f$-and-$m$-algebras we are able to reuse much of the core of
the definitions of the free monad structure we defined in
\autoref{sec:construct-free-monads}.

We emphasise that the result we present here is not new; Hyland
\emph{et al.} have already demonstrated, albeit with a different proof
technique, that the construction we give below in
\autoref{sec:construct-coproducts} actually defines the monad
coproduct. A special case of this result, where the free monad part of
the construction is the free monad over the identity functor, has also
been previously presented by Pir{\'o}g and Gibbons
\cite{pirog12tracing}. Our contribution is two show that the use of
$f$-and-$m$-algebras simplifies and elucidates the definitions
involved.

\subsection{Free monads}
\label{sec:free-monads}

In this section, we give the formal definition of the free monad
interface, and give a brief example showing how free monads provide a
powerful way of writing effectful programs that have multiple
interpretations.

\begin{definition}\label{defn:freemonad}
  Let $(f, \mathit{fmap}_f)$ be a functor. A \emph{free monad} on
  $(f,\mathit{fmap}_f)$ is a monad
  \begin{displaymath}
    (\mathit{FreeM}~f, \mathit{fmap}_{\mathit{FreeM}~f}, \mathit{return}_{\mathit{FreeM}~f}, \mathit{join}_{\mathit{FreeM}~f})
  \end{displaymath}
  equipped with a function:
  \begin{displaymath}
    \mathit{wrap}_f :: f~(\mathit{FreeM}~f~a) \to \mathit{FreeM}~f~a
  \end{displaymath}
  that satisfies:
  \begin{align}
    \label{eq:wrap-natural}
    \mathit{wrap}_f \circ \mathit{fmap}_f~(\mathit{fmap}_{\mathit{FreeM}~f}~g) &= \mathit{fmap}_{\mathit{FreeM}~f}~g \circ \mathit{wrap}_f \\
    \label{eq:wrap-join}
    \mathit{wrap}_f \circ \mathit{fmap}_f~\mathit{join}_{\mathit{FreeM}~f} &= \mathit{join}_{\mathit{FreeM}~f} \circ \mathit{wrap}_f
  \end{align}
  and such that for every monad $(m, \mathit{fmap}_m,
  \mathit{return_m}, \mathit{join}_m)$ and $g :: f~a \to m~a$, such
  that $g$ is natural:
  \begin{displaymath}
    g \circ \mathit{fmap}_f~k = \mathit{fmap}_m~k \circ g
  \end{displaymath}
  there is a unique monad morphism $\fmext{g} :: \mathit{FreeM}~f~a
  \to m~a$ such that:
  \begin{displaymath}
    \mathit{join}_m \circ \mathit{fmap}_m~\fmext{g} \circ g = \fmext{g} \circ \mathit{wrap}_f
  \end{displaymath}
\end{definition}

An alternative but equivalent definition of free monad, which is
slightly more standard from a categorical point of view, has the type
of $\mathit{wrap}_f$ as $f~a \to \mathit{FreeM}~f~a$. We choose the
form in \defref{defn:freemonad} because it is more convenient for
programming.

The following lemma is an immediate consequence of the definition of
free monad, and can be taken as another alternative definition in
terms of isomorphisms of collections of morphisms. It will be useful
when we come to define the coproduct of free monads with arbitrary
monads in terms of $f$-and-$m$-algebras in
\autoref{sec:construct-coproducts} below.

\begin{lemma}
  If $(\mathit{FreeM}~f, \mathit{fmap}_{\mathit{FreeM}~f},
  \mathit{return}_{\mathit{FreeM}~f},
  \mathit{join}_{\mathit{FreeM}~f})$ is a free monad for a functor
  $(f, \mathit{fmap}_f)$, then the operation $\fmext{-} :: (\forall
  a.~f~a \to m~a) \to (\forall a.~\mathit{FreeM}~f~a \to m~a)$ is a
  bijection between natural transformations and monad morphisms. The
  inverse operation can be defined as follows:
  \begin{displaymath}
    \begin{array}{l}
      \fmext{-}^{-1} :: (\forall a.~\mathit{FreeM}~f~a \to m~a) \to (\forall a.~f~a \to m~a) \\
      \fmext{h}^{-1} = h \circ \mathit{wrap}_f \circ \mathit{fmap}_f~\mathit{return}_{\mathit{FreeM}~f}
    \end{array}
  \end{displaymath}
\end{lemma}

One way of explaining the free monad abstraction is in terms of
expressions with variables, and substitution. Under this reading, the
functor $(f,\mathit{fmap}_f)$ describes the constructors that can be
used to make expressions, and a value of type $\mathit{FreeM}~f~a$ is
an expression comprised of the constructors from $f$ and variables
from $a$. The $\mathit{join}_{\mathit{FreeM}~f}$ part of the monad
structure provides substitution of expressions into other expressions,
and the extension $\fmext{g}$ allows us to interpret a whole
expression if we can interpret all the constructors.

Another reading, which is more in line with our general theme of
computational effects, is in terms of sequences of ``commands''. We
think of the functor $(f, \mathit{fmap}_f)$ as describing a collection
of possible commands that can be issued by a program. For example, the
functor $(\mathit{ReaderF}~a, \mathit{fmap}_{\mathit{ReaderF}~a})$,
that we define now, describes a single command of reading a value from
some input. The $\mathit{ReaderF}~a$ functor is defined as follows:
\begin{displaymath}
  \begin{array}{@{}l@{\hspace{2em}}l}
    \begin{array}{@{}l}
      \kw{data}~\mathit{ReaderF}~a~x \\
      \quad
      \begin{array}{c@{\hspace{0.3em}}l}
        = & \mathsf{Read}~(a \to x)
      \end{array}
    \end{array}
    &
    \begin{array}{@{}l}
      \mathit{fmap}_{\mathit{ReaderF}~a} :: (x \to y) \to \mathit{ReaderF}~a~x \to \mathit{ReaderF}~a~y \\
      \mathit{fmap}_{\mathit{ReaderF}~a}~g~(\mathsf{Read}~k) = \mathsf{Read}~(g \circ k)
    \end{array}
  \end{array}
\end{displaymath}
We think of values of type $\mathit{FreeM}~(\mathit{ReaderF}~a)~b$ as
sequences of read commands, eventually yielding a value of type
$b$. We use the $\mathit{wrap}_{\mathit{ReaderF}~a}$ part of the free
monad interface to define a primitive read operation:
\begin{displaymath}
  \begin{array}{@{}l}
    \mathit{read} :: \mathit{FreeM}~(\mathit{ReaderF}~a)~a \\
    \mathit{read} = \mathit{wrap}_{\mathit{ReaderF}~a}~(\mathsf{Read}~\mathit{return}_{\mathit{FreeM}~(\mathit{ReaderF}~a)})
  \end{array}
\end{displaymath}
As every free monad is a monad, we can use Haskell's $\kw{do}$
notation to sequence individual commands. For example, here is a
simple program that reads two strings from some input, and returns
them as a pair in the opposite order.
\begin{displaymath}
  \begin{array}{@{}l}
  \mathit{swapRead} :: \mathit{FreeM}~(\mathit{ReaderF}~\mathit{String})~(\mathit{String},\mathit{String}) \\
  \mathit{swapRead} = \kw{do}~\{ s_1 \leftarrow \mathit{read}; s_2 \leftarrow \mathit{read}; \mathit{return}~(s_2,s_1) \}
\end{array}
\end{displaymath}

The free monad interface gives us considerable flexibility in how we
actually interpret the $\mathit{read}$ commands. For example, we can
interpret each $\mathit{read}$ command as reading a line from the
terminal by defining a transformation from
$\mathit{ReaderF}~\mathit{String}$ to $\mathit{IO}$, using the
standard Haskell function $\mathit{getLine}$ to do the actual reading:
\begin{displaymath}
  \begin{array}{@{}l}
    \mathit{useGetLine} :: \mathit{ReaderF}~\mathit{String}~a \to \mathit{IO}~a \\
    \mathit{useGetLine}~(\mathsf{Read}~k) = \kw{do}~\{ s \leftarrow \mathit{getLine}; \mathit{return}~(k~s) \}
  \end{array}
\end{displaymath}
The free monad interface now provides a way to extend this
interpretation of individual commands to sequences of commmands:
\begin{displaymath}
  \fmext{\mathit{useGetLine}} :: \mathit{FreeM}~(\mathit{ReaderF}~a)~a \to \mathit{IO}~a
\end{displaymath}
Applying $\fmext{\mathit{useGetLine}}$ to $\mathit{swapRead}$ results
in the following interaction, where the second and third lines are
entered by the user, and the final line is printed by the Haskell
implementation:
\begin{displaymath}
  \begin{array}{@{}l}
    >~\fmext{\mathit{useGetLine}}~\mathit{swapRead} \\
    \texttt{"free"} \\
    \texttt{"monad"} \\
    (\texttt{"monad"}, \texttt{"free"})
  \end{array}
\end{displaymath}

The free monad interface provides us with a powerful way of giving
multiple interpretations to effectful commands. Moreover, it is easy
to extend the language of commands simply by extending the functor
$f$. Swierstra \cite{swierstra08data} demonstrates a convenient method
in Haskell for dealing with modular construction of functors for
describing commands in free monads. However, explicitly naming every
additional command that we wish to be able to perform can be
tedious. Sometimes, we simply want access to effects in a known monad
$m$. For example, we may know that we want to execute concrete
$\mathit{IO}$ actions as well as abstract read operations. One
possible way of accomplishing this is to ensure that there is an
additional constructor to the functor $f$ that describes an additional
``abstract command'' of performing an effect in the chosen monad. For
example, we could extend the $\mathit{ReaderF}~a$ functor like so to
add the possibility of concrete effects in a monad $m$:
\begin{displaymath}
  \kw{data}~\mathit{ReaderMF}~m~a~x = \mathsf{Read}~(a \to x) \mathrel| \mathsf{Act}~(m~x)
\end{displaymath}
This approach has the disadvantage that the effects of the monad $m$
must now be handled by the interpretation of the other abstract
commands. For example, we would have to add another case to the
$\mathit{useGetLine}$ function to handle the $\mathsf{Act}$
case. Thus, we would be forced to combine the interpretation of the
pure data representing abstract commands with the interpretation of
concrete effects. As we have observed in the case of list append in
\autoref{sec:direct-eappend}, the mingling of such concerns can lead
to unnecessarily complicated reasoning. Fortunately, a conceptually
simpler solution is available: we take the coproduct of the free monad
for the funcor $f$ that describes our abstract effects with the monad
$m$ that describes our concrete effects. We define the coproduct of
two monads in \autoref{sec:coproducts-of-monads}, below, and
demonstrate how monad coproducts cleanly combine abstract effects with
concrete effects. Before that, in the next section, we demonstrate how
to construct free monads from initial $f$-algebras.

\subsection{Constructing free monads, via $f$-algebras}
\label{sec:construct-free-monads}

\begin{figure}
  Let $(f,\mathit{fmap}_f)$ be a functor, and define:
  \begin{displaymath}
    \begin{array}{l}
      \kw{data}~\mathit{FreeMF}~f~a~x \\
      \quad\begin{array}{cl}
        = & \mathsf{Var}~a \\
        | & \mathsf{Term}~(f~x)
      \end{array} \\
      \\
      \mathit{fmap}_{\mathit{FreeMF}} :: (x \to y) \to \mathit{FreeMF}~f~a~x \to \mathit{FreeMF}~f~a~y \\
      \begin{array}{@{}l@{\hspace{0.3em}}l@{\hspace{0.3em}}l@{\hspace{0.3em}}c@{\hspace{0.3em}}l}
        \mathit{fmap}_{\mathit{FreeMF}} & g & (\mathsf{Var}~a) & = & \mathsf{Var}~a \\
        \mathit{fmap}_{\mathit{FreeMF}} & g & (\mathsf{Term}~\mathit{fx}) & = & \mathsf{Term}~(\mathit{fmap}_f~g~\mathit{fx})
      \end{array}
    \end{array}
  \end{displaymath}

  \bigskip

  Free monads:
  \begin{displaymath}
    \begin{array}{@{}l}
      \kw{type}~\mathit{FreeM}~f~a = \mu(\mathit{FreeMF~f~a}) \\
      \\
      \begin{array}{@{}l}
        \mathit{fmap}_{\mathit{FreeM}~f} :: (a \to b) \to \mathit{FreeM}~f~a \to \mathit{FreeM}~f~b \\
        \mathit{fmap}_{\mathit{FreeM}~f}~g = \fold{\mathit{fmapAlgebra}} \\
        \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
          \kw{where} & \mathit{fmapAlgebra}~(\mathsf{Var}~a) &=& \mathit{construct}~(\mathsf{Var}~(g~a)) \\
          & \mathit{fmapAlgebra}~(\mathsf{Term}~x) &=& \mathit{construct}~(\mathsf{Term}~x)
        \end{array}
      \end{array} \\
      \\
      \begin{array}{@{}l}
        \mathit{return}_{\mathit{FreeM}~f} :: a \to \mathit{FreeM}~f~a \\
        \mathit{return}_{\mathit{FreeM}~f}~a = \mathit{construct}~(\mathsf{Var}~a)
      \end{array} \\
      \\
      \begin{array}{@{}l}
        \mathit{join}_{\mathit{FreeM}~f} :: \mathit{FreeM}~f~(\mathit{FreeM}~f~a) \to \mathit{FreeM}~f~b \\
        \mathit{join}_{\mathit{FreeM}~f} = \fold{\mathit{joinAlgebra}} \\
        \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
          \kw{where} & \mathit{joinAlgebra}~(\mathsf{Var}~x) &=& x \\
          & \mathit{joinAlgebra}~(\mathsf{Term}~x) &=& \mathit{construct}~(\mathsf{Term}~x)
        \end{array}
      \end{array} \\
      \\
      \begin{array}{@{}l}
        \mathit{wrap}_f :: f~(\mathit{FreeM}~f~a) \to \mathit{FreeM}~f~a \\
        \mathit{wrap}_f~x = \mathit{construct}~(\mathsf{Term}~x)
      \end{array} \\
      \\
      \begin{array}{@{}l}
        \fmext{-} :: (f~a \to m~a) \to \mathit{FreeM}~f~a \to m~a \\
        \fmext{g} = \fold{\mathit{extAlgebra}} \\
        \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
          \kw{where} & \mathit{extAlgebra}~(\mathsf{Var}~a) &=& \mathit{return}_m~a \\
          & \mathit{extAlgebra}~(\mathsf{Term}~x) &=& \mathit{join}_m~(g~x)
        \end{array}
      \end{array}
    \end{array}
  \end{displaymath}
  
  \caption{Constructing free monads via $f$-algebras}
\label{fig:construct-free-monads}
\end{figure}

\autoref{fig:construct-free-monads} demonstrates how the free monad
interface we defined in the previous section may be implemented in
terms of initial $(\mathit{FreeMF}~f~a)$-algebras, where the functor
$\mathit{FreeMF}~f~a$ is also defined in
\autoref{fig:construct-free-monads}. The key idea is that a value of
type $\mathit{FreeM}~f~a$ is constructed from layers of ``terms''
described by the functor $f$, represented by $\mathsf{Term}$
constructor, and terminated by ``variables'', represented by the
$\mathsf{Var}$ constructor.

The definition of the free monad structure is relatively
straightforward, using the functions induced by the initial algebra
property of $\mu (\mathit{FreeMF}~f~a)$. Each of the properties
required of free monads is proved by making use of
\proofprinref{pp:initial-alg}. When we construct the coproduct of a
free monad with an arbitrary monad in
\autoref{sec:construct-coproducts} we will be able to reuse much of
the definitions in \autoref{fig:construct-free-monads}.

\subsection{Coproducts of monads}
\label{sec:coproducts-of-monads}

\newcommand{\cprd}[2]{#1\mathord{+}#2}

In the introduction to this section, we intuitively described monad
coproducts as the ``least commitment'' combination of a pair of
monads. Formally, this least commitment aspect is realised as the
existence of a \emph{unique} monad morphism out of a coproduct, for
every way of interpreting its consistuent parts. Coproducts of monads
are precisely coproducts in the category of monads and monad
morphisms. The following definition sets out the precise conditions:
\begin{definition}\label{defn:coproducts}
  Let $(m_1, \mathit{fmap}_{m_1}, \mathit{return}_{m_1}, \mathit{join}_{m_1})$ and $(m_2,
  \mathit{fmap}_{m_1}, \mathit{return}_{m_2}, \mathit{join}_{m_2})$ be a pair of monads. A \emph{coproduct} of these two monads is a
  monad $(\cprd{m_1}{m_2}, \mathit{fmap}_{\cprd{m_1}{m_2}}, \mathit{return}_{\cprd{m_1}{m_2}},
  \mathit{join}_{\cprd{m_1}{m_2}})$ along with a pair of monad morphisms:
  \begin{displaymath}
    \begin{array}{rcl}
      \mathit{inj}_1 & :: & m_1~a \to (\cprd{m_1}{m_2})~a \\
      \mathit{inj}_2 & :: & m_1~a \to (\cprd{m_1}{m_2})~a
    \end{array}
  \end{displaymath}
  and the property that for any monad $(m,\mathit{fmap}_m,
  \mathit{return}_m, \mathit{join}_m)$ and pair of monad morphisms
  $g_1 : m_1~a \to m~a$ and $g_2 : m_2~a \to m~a$ there is a
  \emph{unique} monad morphism $[g_1,g_2] : (\cprd{m_1}{m_2})~a \to
  m~a$ such that
  \begin{displaymath}
    \begin{array}{rcl}
      {}[g_1,g_2] \circ \mathit{inj}_1 & = & g_1 \\
      {}[g_1,g_2] \circ \mathit{inj}_2 & = & g_2
    \end{array}
  \end{displaymath}
\end{definition}

In \autoref{sec:free-monads}, we demonstrated how the free monad over
a functor describing read commands allowed us to provide multiple
interpretations of ``reading''. 
% We now show how we can use the
% coproduct interface to describe computations that interleave abstract
% read operations with concrete $\mathit{IO}$ effects. 
The monad coproduct
$\cprd{(\mathit{FreeM}~(\mathit{ReaderF}~\mathit{String}))}{\mathit{IO}}$
freely combines the abstract read commands described by the functor
$\mathit{ReaderF}~\mathit{String}$ with the concrete input/output
actions of the $\mathit{IO}$ monad. We view
$\cprd{(\mathit{FreeM}~(\mathit{ReaderF}~\mathit{String}))}{\mathit{IO}}$
as the modular reconstruction of the Iteratee monad
$\mathit{Reader}~m~a$ we presented in
\autoref{sec:motivate-interleaving}.

The following example extends the $\mathit{swapRead}$ example from
\autoref{sec:free-monads} to perform an input/output effect as well as
two abstract read effects.  The $\mathit{inj_1}$ and $\mathit{inj_2}$
components of the coproduct monad interface allow us to lift effectful
computations from the free monad and the $\mathit{IO}$ monad respectively:
\begin{displaymath}
  \begin{array}{@{}l}
    \mathit{swapRead2} :: (\cprd{(\mathit{FreeM}~(\mathit{ReaderF}~\mathit{String}))}{\mathit{IO}})~() \\
    \mathit{swapRead2} = \kw{do}~
    \begin{array}[t]{@{}l}
      s_1 \leftarrow \mathit{inj_1}~\mathit{read} \\
      s_2 \leftarrow \mathit{inj_1}~\mathit{read} \\
      \mathit{inj_2}~(\mathit{putStrLn}~(\texttt{"("} \dplus s_2 \dplus \texttt{","} \dplus s_1 \dplus \texttt{")"}))
    \end{array}
  \end{array}
\end{displaymath}
This program executes two read commands, which we have not yet
provided an interpretation for, to read a pair of strings, and then
executes a concrete $\mathit{IO}$ action to print the two strings in
reverse order to the terminal.

We can provide an interpretation for the abstract $\mathit{read}$
operations by combining the coproduct interface with the free monad
interface. For example, to interpret the read commands as reading from
the terminal, we use the $\mathit{useGetLine}$ interpretation from
\autoref{sec:free-monads}:
\begin{displaymath}
  [\fmext{\mathit{useGetLine}}, \mathit{id}] :: (\cprd{(\mathit{FreeM}~(\mathit{ReaderF}~\mathit{String}))}{\mathit{IO}})~a \to \mathit{IO}~a
\end{displaymath}

Alternatively, we can interpret the abstract $\mathit{read}$ commands
as reading from a file handle. The function $\mathit{useFileHandle}$
describes how to execute single reads on a file handle as an $\mathit{IO}$ action:
\begin{displaymath}
  \begin{array}{@{}l}
    \mathit{useFileHandle} :: \mathit{Handle} \to \mathit{ReaderF}~\mathit{String}~a \to \mathit{IO}~a \\
    \mathit{useFileHandle}~h~(\mathsf{Read}~k) = \kw{do}~\{ s \leftarrow \mathit{hGetLine}~h; \mathit{return}~(k~s) \}
  \end{array}
\end{displaymath}
Again, we can combine the free monad and monad coproduct interfaces to
extend this interpretation of individual abstract $\mathit{read}$
commands to all sequences of $\mathit{read}$ commands interleaved with
arbitrary $\mathit{IO}$ actions:
\begin{displaymath}
  \lambda h.~[\fmext{\mathit{useFileHandle}~h}, \mathit{id}] :: \mathit{Handle} \to (\cprd{(\mathit{FreeM}~(\mathit{ReaderF}~\mathit{String}))}{\mathit{IO}})~a \to \mathit{IO}~a
\end{displaymath}

\subsection{Constructing coproducts with free monads via $f$-and-$m$-algebras}
\label{sec:construct-coproducts}

\begin{figure}
  \centering
  \begin{displaymath}
    \begin{array}{@{}l}
      \kw{type}~(\cprd{(\mathit{FreeM}~f)}{m})~a = \mu(\mathit{FreeMF}~f~a|m) \\
      \\
      \begin{array}{@{}l}
        \mathit{fmap}_{\cprd{(\mathit{FreeM}~f)}{m}} :: (a \to b) \to (\cprd{(\mathit{FreeM}~f)}{m})~a \to (\cprd{(\mathit{FreeM}~f)}{m})~b \\
        \mathit{fmap}_{\cprd{(\mathit{FreeM}~f)}{m}}~g = \eFold{\mathit{fmapAlgebra}}{\mathit{construct_m}} \\
        \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
          \kw{where} & \mathit{fmapAlgebra}~(\mathsf{Var}~a) &=& \mathit{construct}_{\mathit{FreeMF}~f~b}~(\mathsf{Var}~(g~a)) \\
          & \mathit{fmapAlgebra}~(\mathsf{Term}~x) &=& \mathit{construct}_{\mathit{FreeMF}~f~b}~(\mathsf{Term}~x)
        \end{array}
      \end{array} \\
      \\
      \begin{array}{@{}l}
        \mathit{return}_{\cprd{(\mathit{FreeM}~f)}{m}} :: a \to (\cprd{(\mathit{FreeM}~f)}{m})~a \\
        \mathit{return}_{\cprd{(\mathit{FreeM}~f)}{m}}~a = \mathit{construct}_{\mathit{FreeMF}~f~a}~(\mathsf{Var}~a)
      \end{array} \\
      \\
      \begin{array}{@{}l}
        \mathit{join}_{\cprd{(\mathit{FreeM}~f)}{m}} :: (\cprd{(\mathit{FreeM}~f)}{m})~((\cprd{(\mathit{FreeM}~f)}{m})~a) \to (\cprd{(\mathit{FreeM}~f)}{m})~b \\
        \mathit{join}_{\cprd{(\mathit{FreeM}~f)}{m}} = \eFold{\mathit{joinAlgebra}}{\mathit{construct}_m} \\
        \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
          \kw{where} & \mathit{joinAlgebra}~(\mathsf{Var}~x) &=& x \\
          & \mathit{joinAlgebra}~(\mathsf{Term}~x) &=& \mathit{construct}~(\mathsf{Term}~x)
        \end{array}
      \end{array} \\
      \\
      \mathit{inj_1} :: \mathit{FreeM}~f~a \to (\cprd{(\mathit{FreeM}~f)}{m})~a \\
      \mathit{inj_1} = \fmext{\mathit{construct}_{\mathit{FreeMF}~f~a} \circ \mathsf{Term}} \\
      \\
      \mathit{inj_2} :: m~a \to (\cprd{(\mathit{FreeM}~f)}{m})~a \\
      \mathit{inj_2} = \mathit{construct}_m \circ \mathit{fmap}_m~\mathit{return}_{\cprd{(\mathit{FreeM}~f)}{m}}\\
      \\
      \begin{array}{@{}l}
        {}[-,-] :: (\forall a.~\mathit{FreeM}~f~a \to m'~a) \to (\forall a.~m~a \to m'~a) \to (\cprd{(\mathit{FreeM}~f)}{m})~a \to m'~a \\
        {}[g_1,g_2] = \eFold{\mathit{caseAlgebra}}{\mathit{join}_{m'} \circ g_2} \\
        \quad\begin{array}{r@{\hspace{0.4em}}l@{\hspace{0.5em}}c@{\hspace{0.5em}}l}
          \kw{where} & \mathit{caseAlgebra}~(\mathsf{Var}~a) &=& \mathit{return}_{m'}~a \\
          & \mathit{caseAlgebra}~(\mathsf{Term}~x) &=& \mathit{join}_{m'}~(\fmext{g_1}^{-1}~x)
        \end{array}
      \end{array}
    \end{array}
  \end{displaymath}
  \caption{Construction of coproducts with free monads via $f$-and-$m$-algebras}
  \label{fig:construct-coproduct}
\end{figure}

\autoref{fig:construct-coproduct} demonstrates the construction of the
coproduct of a free monad with an arbitrary monad $m$ in terms of
initial $f$-and-$m$-algebras. We program against the abstract
interface of initial $f$-and-$m$-algebras, rather relying on any
particular implementation. If we take the implementation that we
presented in \autoref{sec:impl-f-and-m}, then the definition of
$(\cprd{(\mathit{FreeM}~f)}{m})~a$ unfolds to be
$m~(\mathit{Mu}~(\mathit{FreeMF}~f~a \fcompose m))$, which is exactly
the Haskell translation of the construction that Hyland \emph{et al.}
present.

The definitions of the basic monad structure -- $\mathit{fmap}$,
$\mathit{return}$ and $\mathit{join}$ -- are almost identical to the
corresponding definitions for the free monad in
\autoref{fig:construct-free-monads}. This demonstrates the same
feature of the use of $f$-and-$m$-algebras that we saw when defining
the effectful list append in \autoref{sec:f-and-m-append}: the clean
separation of pure and effectful concerns allows us to reuse much of
the work we performed in the non-effectful case. The proofs that these
definitions actually form a monad carry over just as they did for the
list append example.

For the monad coproduct structure, we use the pure and effectful parts
of the initial $(\mathit{FreeMF}~f~a)$-and-$m$-algebra stucture --
$\mathit{construct}_{\mathit{FreeMF}~f~a}$ and $\mathit{construct}_m$
-- for the first and second injections $\mathit{inj}_1$ and
$\mathit{inj}_2$ respectively. Since
$\mathit{construct}_{\mathit{FreeMF}~f~a}$ injects an single abstract
command from $f$ into the coproduct, we use the free monad structure
to inject all the commands into the coproduct.

In order for the use of the $(\mathit{FreeMF}~f~a)$-and-$m$-algebra
initiality to construct a function on $\mu(\mathit{FreeMF}~f~a|m)$ in
the definition of $[-,-]$ to be valid, we must check that the second
component of $\eFold{\mathit{caseAlgebra}}{\mathit{join_{m'}} \circ
  g_2}$ is actually an $m$-Eilenberg-Moore-algebra. For the first law
(\autoref{eq:em-alg-return}), we reason as follows:
\begin{displaymath}
  \begin{array}{cl}
    & \mathit{join}_{m'} \circ g_2 \circ \mathit{return}_m \\
    =&\eqAnnotation{$g_2$ is a monad morphism (\autoref{eq:monad-mor-return})} \\
    & \mathit{join}_{m'} \circ \mathit{return}_{m'} \\
    =&\eqAnnotation{monad law: $\mathit{join}_{m'} \circ \mathit{return}_{m'} = \mathit{id}$ (\autoref{eq:monad-join-return})} \\
    & \mathit{id}
  \end{array}
\end{displaymath}
The second law (\autoref{eq:em-alg-join}) is also straightforward:
\begin{displaymath}
  \begin{array}{cl}
    & \mathit{join}_{m'} \circ g_2 \circ \mathit{join}_m \\
    =&\eqAnnotation{$g_2$ is a monad morphism (\autoref{eq:monad-mor-join})} \\
    & \mathit{join}_{m'} \circ \mathit{join}_{m'} \circ g_2 \circ \mathit{fmap}_m~g_2 \\
    =&\eqAnnotation{monad law: $\mathit{join}_{m'} \circ \mathit{join}_{m'} = \mathit{join}_{m'} \circ \mathit{fmap}_m'~\mathit{join}_{m'}$ (\autoref{eq:monad-join-join})} \\
    & \mathit{join}_{m'} \circ \mathit{fmap}_{m'}~\mathit{join}_{m'} \circ g_2 \circ \mathit{fmap}_m~g_2 \\
    =&\eqAnnotation{naturality of $g_2$} \\
    & \mathit{join}_{m'} \circ g_2 \circ \mathit{fmap}_{m}~\mathit{join}_{m'} \circ \mathit{fmap}_m~g_2 \\
    =&\eqAnnotation{$\mathit{fmap}_m$ preserves function composition (\autoref{eq:fmap-comp})} \\
    & \mathit{join}_{m'} \circ g_2 \circ \mathit{fmap}_{m}~(\mathit{join}_{m'} \circ g_2)
  \end{array}
\end{displaymath}
The proof that $[g_1,g_2]$ satisfies the conditions specified in
\defref{defn:coproducts} is remarkably similar to the proof that
$\fmext{g}$ satisfies the required properties for the free monad
specification. This is another testament to the power of
$f$-and-$m$-algebras.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{jfp}
\bibliography{paper}

\end{document}
